
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>16.1. Ước lượng MLE cho phân phối Gaussian đa chiều &#8212; Deep AI KhanhBlog</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"TeX": {"Macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/GMM.html" />
    <link rel="shortcut icon" href="../_static/logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="17. Giảm chiều dữ liệu" href="index_PCA.html" />
    <link rel="prev" title="16. Gaussian Mixture Model" href="index_GMM.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/ML_course_logos.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep AI KhanhBlog</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Lời nói đầu
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../contents.html">
   Các chương dự kiến
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/main_contents.html">
   Mục tiêu cuốn sách
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../latex.html">
   Latex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../grossary.html">
   Bảng thuật ngữ
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Phụ lục
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/appendix_dtypes.html">
   1. Định dạng dữ liệu
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html">
     1.1. Các định dạng số, boolean và ký tự
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_pandas.html">
   2. Pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html">
     2.1. Khởi tạo dataframe
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_numpy.html">
   3. Numpy
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html">
     3.1. Khởi tạo một mảng trên numpy
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_matplotlib.html">
   4. Matplotlib
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html">
     4.1. Format chung của một biểu đồ trên matplotlib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_OOP.html">
   5. Lập trình hướng đối tượng (Object Oriented Programming - OOP)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html">
     5.1. Class và Object
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_pipeline.html">
   6. Sklearn Pipeline
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html">
     6.1. Thiết kế pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_Convex_Opt.html">
   7. Giới thiệu chung về optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html">
     7.1. Bài toán dạng tổng quát
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Đại số tuyến tính
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html">
   1. Đại số tuyến tính
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html">
   1. Giải tích tích phân
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Xác suất
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html">
   1. Xác suất
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index_MLIntroduce.html">
   1. Khái quát Machine Learning
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_prediction.html">
   2. Bài toán dự báo
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html">
     2.1. Ứng dụng của hồi qui tuyến tính
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_RidgedRegression.html">
   2.2. Hồi qui Ridge và Lasso
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html">
     2.2.2. Hồi qui Ridge
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_classification.html">
   3. Bài toán phân loại
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html">
     3.1. Hồi qui Logistic
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_OvfAndUdf.html">
   4. Độ chệch (
   <em>
    bias
   </em>
   ) và phương sai (
   <em>
    variance
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html">
     4.1. Sự đánh đổi giữa độ chệch và phương sai
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_ModelMetric.html">
   5. Thước đo mô hình phân loại
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html">
     5.1. Bộ dữ liệu
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_creditScorecard.html">
   6. Ứng dụng mô hình scorecard
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="creditScorecard.html">
     6.1. Phương pháp chuyên gia và mô hình
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_SVM.html">
   7. Giới thiệu về SVM
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html">
     7.1. Hàm mất mát của SVM
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_DecisionTree.html">
   8. Khái niệm về cây quyết định
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html">
     8.1. Mô hình cây quyết định (
     <em>
      decision tree
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_RandomForest.html">
   9. Giới thiệu về mô hình rừng cây (
   <em>
    Random Forest
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html">
     9.1. Ý tưởng của mô hình rừng cây
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_Bayes.html">
   10. Bạn là
   <em>
    Tần suất
   </em>
   (
   <em>
    Frequentist
   </em>
   ) hay
   <em>
    Bayesian
   </em>
   ?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html">
     10.1. Ước lượng hợp lý tối đa (
     <em>
      Maximum Likelihood Function - MLE
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_FeatureEngineering.html">
   11. Giới thiệu về feature engineering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html">
     11.1. Feature Engineering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_Boosting.html">
   12. Phương pháp tăng cường (
   <em>
    Boosting
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Boosting.html">
     12.1. AdaBoosting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_KMeans.html">
   13. k-Means Clustering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html">
     13.1. Các bước của thuật toán k-Means Clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_HierarchicalClustering.html">
   14. Hierarchical Clustering (
   <em>
    phân cụm phân cấp
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html">
     14.1. Chiến lược hợp nhất (
     <em>
      agglomerative
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_DBSCAN.html">
   15. DBSCAN
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html">
     15.1. Phương pháp phân cụm dựa trên mật độ (
     <em>
      Density-Based Clustering
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index_GMM.html">
   16. Gaussian Mixture Model
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     16.1. Ước lượng MLE cho
     <em>
      phân phối Gaussian đa chiều
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_PCA.html">
   17. Giảm chiều dữ liệu
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
  <label for="toctree-checkbox-24">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="PCA.html">
     17.1. Phương pháp phân tích suy biến
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Đóng góp từ những tác giả khác
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/fubini_and_riemann.html">
   Tích phân Riemann và định lý Fubini
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/information_theory.html">
   Lý thuyết thông tin
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/ch_ml/GMM.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ch_ml/GMM.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/phamdinhkhanh/deepai-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/phamdinhkhanh/deepai-book/issues/new?title=Issue%20on%20page%20%2Fch_ml/GMM.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/phamdinhkhanh/deepai-book/edit/main/book/ch_ml/GMM.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/phamdinhkhanh/deepai-book/main?urlpath=tree/book/ch_ml/GMM.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   16.1. Ước lượng MLE cho
   <em>
    phân phối Gaussian đa chiều
   </em>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-mixture-model">
   16.2. Gaussian Mixture Model
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#uoc-luong-hop-ly-toi-da">
     16.2.1. Ước lượng hợp lý tối đa
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#khai-trien-ham-auxilary">
     16.2.2. Khai triển hàm
     <em>
      auxilary
     </em>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cac-buoc-trong-gmm">
     16.2.3. Các bước trong GMM
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#thuc-hanh-mo-hinh">
   16.4. Thực hành mô hình
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tien-xu-ly-du-lieu">
     16.4.1. Tiền xử lý dữ liệu
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mo-hinh-gaussian-mixture">
     16.4.2. Mô hình
     <em>
      Gaussian Mixture
     </em>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lua-chon-sieu-tham-so-cho-mo-hinh-gmm">
     16.4.3. Lựa chọn siêu tham số cho mô hình
     <em>
      GMM
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tong-ket">
   16.5. Tổng kết
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bai-tap">
   16.6. Bài tập
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tai-lieu-tham-khao">
   16.7. Tài liệu tham khảo
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="uoc-luong-mle-cho-phan-phoi-gaussian-da-chieu">
<h1>16.1. Ước lượng MLE cho <em>phân phối Gaussian đa chiều</em><a class="headerlink" href="#uoc-luong-mle-cho-phan-phoi-gaussian-da-chieu" title="Permalink to this headline">¶</a></h1>
<p>Giả sử chúng ta có một bộ dữ liệu gồm các quan sát độc lập và xác định (iid) là <span class="math notranslate nohighlight">\(\mathcal{D} = \{ \mathbf{x}_1, \mathbf{x}_2. \dots, \mathbf{x}_N \}\)</span>. Trong đó mỗi một <span class="math notranslate nohighlight">\(\mathbf{x}_i \in \mathbb{R}^{d}\)</span> là một véc tơ quan sát trong không gian <span class="math notranslate nohighlight">\(d\)</span> chiều được lấy mẫu từ <em>phân phối Gaussian đa chiều</em>. Chúng ta cần ước lượng phân phối của tham số thông qua <em>ước lượng hợp lý tối đa MLE</em>.</p>
<p><span class="math notranslate nohighlight">\(N\)</span> quan sát được giả định là độc lập. Do đó hàm hợp lý của phân phối của <span class="math notranslate nohighlight">\(N\)</span> quan sát sẽ bằng tích của xác suất trên từng quan sát:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
	l(\mathbf{ \mu, \Sigma }|\mathcal{D}) &amp; = \log \prod_{i=1}^m f_{\mathbf{x}_{i}}(\mathbf{x}_{i} | \mu , \mathbf{\Sigma} )
	\\
	&amp; =  \log  \ \prod_{i=1}^N \frac{1}{(2 \pi)^{d/2} |\mathbf{\Sigma}|^{1/2}} \exp \left( - \frac{1}{2} (\mathbf{x}_{i} - \mu)^{\intercal} \mathbf{\Sigma}^{-1} (\mathbf{x}_{i} - \mu) \right) 
	\\
	&amp; = \sum_{i=1}^N \left( - \frac{d}{2} \log (2 \pi) - \frac{1}{2} \log |\mathbf{\Sigma}|  - \frac{1}{2}   \mathbf{(x}_{i} - \mu)^{\intercal} \mathbf{\Sigma}^{-1} (\mathbf{x}_{i} - \mu)  \right) 
  \\
  &amp; = - \frac{N}{2} \log |\mathbf{\Sigma}| - \sum_{i=1}^N  \frac{1}{2}   \mathbf{(x}_{i} - \mu)^{\intercal} \mathbf{\Sigma}^{-1} (\mathbf{x}_{i} - \mu) - \underbrace{\frac{Nd}{2} \log (2 \pi)}_{C} \\
  &amp; = - \frac{N}{2} \log |\mathbf{\Sigma}| - \sum_{i=1}^N  \frac{1}{2}   \mathbf{(x}_{i} - \mu)^{\intercal} \mathbf{\Sigma}^{-1} (\mathbf{x}_{i} - \mu) + C
\end{aligned}\end{split}\]</div>
<p>Lấy đạo hàm bậc nhất của <em>hàm hợp lý</em> theo <span class="math notranslate nohighlight">\(\mu\)</span> và <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>.</p>
<p><strong>Đạo hàm theo</strong> <span class="math notranslate nohighlight">\(\mu\)</span>:</p>
<p>Để tính toán đạo hàm bậc nhất chúng ta cần áp dụng công thức:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial \mathbf{w}^{\intercal}\mathbf{A}\mathbf{w}}{\partial \mathbf{w}} = 2\mathbf{A}\mathbf{w}\]</div>
<p>Coi <span class="math notranslate nohighlight">\(\mathbf{\Sigma}^{-1} = \mathbf{A}\)</span> và <span class="math notranslate nohighlight">\(\mathbf{x}_i-\mu = \mathbf{w}\)</span>, khi đó:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
	\frac{\partial l(\mathbf{ \mu}, \mathbf{ \Sigma} | \mathcal{D} )}{\partial \mu}  &amp; = &amp; -\sum_{i=1}^N  \mathbf{ \Sigma^{-1}} ( \mathbf{x}_{i} - \mathbf{\mu} ) \\
  &amp; = &amp; \mathbf{ \Sigma^{-1}}(N\mu - \sum_{i=1}^N \mathbf{x}_i)
\\
  &amp; = &amp; 0
\end{eqnarray}\end{split}\]</div>
<p>Nhân cả hai vế của dòng thứ 2 với <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span> về phía ngoài cùng bên trái ta suy ra nghiệm <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> chính là:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
 N\hat{\mu} - \sum_{i=1}^N \mathbf{x}_i &amp; = &amp; 0 \\
 \leftrightarrow \hat{\mu} &amp; = &amp; \frac{\sum_{i=1}^{N} \mathbf{x}_i}{N}
\end{eqnarray}\end{split}\]</div>
<p><strong>Đạo hàm theo</strong> <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>:</p>
<p>Để tính toán đạo hàm theo <span class="math notranslate nohighlight">\(\Sigma\)</span> chúng ta cần áp dụng một số công thức:</p>
<p>1.- Trace của tích ba ma trận không thay đổi nếu hoán vị:</p>
<div class="math notranslate nohighlight">
\[\text{trace}{(\mathbf{ABC})} = \text{trace}{(\mathbf{CAB})} = \text{trace}{(\mathbf{BCA})}\]</div>
<p>2.- Khi <span class="math notranslate nohighlight">\(\mathbf{x}^{\intercal}\mathbf{A}\mathbf{x}\)</span> là một số vô hướng (<em>scalar</em>) thì:</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\intercal}\mathbf{A} \mathbf{x} = \text{trace}(\mathbf{x}^{\intercal}\mathbf{A}\mathbf{x}) = \text{trace}(\mathbf{x}^{\intercal}\mathbf{x}\mathbf{A})\]</div>
<p>3.- Đạo hàm của:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial ~ \text{trace}(\mathbf{AB})}{\partial \mathbf{A}} = \frac{\partial ~ \text{trace}(\mathbf{BA})}{\partial \mathbf{A}} = \mathbf{B}^{\intercal}\]</div>
<p>4.- Đạo hàm của:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial \log(\mathbf{A})}{\partial \mathbf{A}} = \mathbf{A}^{-\intercal}\]</div>
<p>5.- Định thức của một ma trận thì bằng nghịch đảo định thức của ma trận nghịch đảo:</p>
<div class="math notranslate nohighlight">
\[|\mathbf{A}| = \frac{1}{|\mathbf{A}^{-1}|}\]</div>
<p>Chứng minh những công thức trên không quá khó. Xin dành cho bạn đọc như một bài tập.</p>
<p>Ngoài ra từ công thức thứ 2 và 3 ta suy ra:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial}{\partial \mathbf{A}}  \mathbf{x}^{\intercal}\mathbf{A}\mathbf{x} =\frac{\partial}{\partial \mathbf{A}}  \text{trace} ( \mathbf{x}^{\intercal}\mathbf{x}\mathbf{A} ) = [ \mathbf{x}^{\intercal}\mathbf{x}]^{\intercal} =  \mathbf{x}\mathbf{x}^{\intercal}\]</div>
<p>đồng thời hàm hợp lý cũng được biến đổi thành:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{eqnarray}
	l(\mathbf{ \mu, \mathbf{\Sigma}} | \mathcal{D})  &amp; = &amp; C - \frac{N}{2} \log |\mathbf{\Sigma}|  - \frac{1}{2}  \sum_{i=1}^N  (\mathbf{x}_{i} - \mu)^{\intercal} \mathbf{\Sigma}^{-1} (\mathbf{x}_{i} - \mu)   
	\\
	&amp; = &amp; C + \frac{N}{2} \log |\mathbf{\Sigma}^{-1}|  - \frac{1}{2}  \sum_{i=1}^N  \text{trace}\left[ (\mathbf{x}_{i} - \mu)^{\intercal} (\mathbf{x}_{i} - \mu) \mathbf{\Sigma}^{-1}  \right]
\end{eqnarray}
\end{split}\]</div>
<p>Bây giờ chúng ta có thể tính toán đạo hàm theo ma trận <span class="math notranslate nohighlight">\(\mathbf{\Sigma}^{-1}\)</span> như sau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}
	\frac{\partial l(\mathbf{ \mu, \Sigma}|\mathcal{D})}{\partial \mathbf{\Sigma}^{-1}}  &amp; = &amp; \frac{N}{2}\mathbf{\Sigma}^{\intercal} - \frac{1}{2}  \sum_{i=1}^N (\mathbf{x}_{i} - \mu) (\mathbf{x}_{i} - \mu)^{\intercal} \\
&amp; = &amp; \frac{N}{2}\mathbf{\Sigma} - \frac{1}{2}  \sum_{i=1}^N (\mathbf{x}_{i} - \mu) (\mathbf{x}_{i} - \mu)^{\intercal}
  \end{eqnarray}
\end{split}\]</div>
<p>Dòng thứ 2 thu được là vì <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span> là ma trận đối xứng. Như vậy nghiệm <span class="math notranslate nohighlight">\(\hat{\mathbf{\Sigma}}\)</span> chính là:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\frac{N}{2}\hat{\mathbf{\Sigma}} - \frac{1}{2}  \sum_{i=1}^N (\mathbf{x}_{i} - \mu) (\mathbf{x}_{i} - \mu)^{\intercal} &amp; = &amp; 0
\\ \leftrightarrow \hat{\mathbf{\Sigma}} = \frac{\sum_{i=1}^N (\mathbf{x}_{i} - \mu) (\mathbf{x}_{i} - \mu)^{\intercal}}{N}
\end{eqnarray}\end{split}\]</div>
<p>Như vậy ta thu được ước lượng hợp lý tối đa cho các tham số của <em>phân phối Gassian đa chiều</em>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\left\{
\begin{matrix}
\hat{\mu} &amp; = &amp; \frac{\sum_{i=1}^{N} \mathbf{x}_i}{N} = \mathbb{E}(\mathbf{X}) \\
\hat{\mathbf{\Sigma}} &amp; = &amp; \frac{\sum_{i=1}^N (\mathbf{x}_{i} - \mu) (\mathbf{x}_{i} - \mu)^{\intercal}}{N} = \mathbb{Cov}(\mathbf{X})
\end{matrix}
\right.\end{split}
\end{split}\]</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="gaussian-mixture-model">
<h1>16.2. Gaussian Mixture Model<a class="headerlink" href="#gaussian-mixture-model" title="Permalink to this headline">¶</a></h1>
<p><em>Gaussian Mixture Model</em> (viết tắt <em>GMM</em>) là một mô hình phân cụm thuộc lớp bài toán học không giám sát mà phân phối xác suất của mỗi một cụm được giả định là <em>phân phối Gassian đa chiều</em>. Sở dĩ mô hình được gọi là <em>Mixture</em> là vì xác suất của mỗi điểm dữ liệu không chỉ phụ thuộc vào một phân phối <em>Gaussian</em> duy nhất mà là kết hợp từ nhiều phân phối <em>Gaussian</em> khác nhau từ mỗi cụm.</p>
<p><img alt="" src="https://imgur.com/6OvUE6Z.png" /></p>
<p><strong>Hình 3</strong>: <em>Phân phối Gaussian đa chiều</em> với số cụm <span class="math notranslate nohighlight">\(k=3\)</span> đối với bộ dữ liệu một chiều (bên trái) và hai chiều (bên phải).</p>
<p>Mục tiêu của mô hình <em>GMM</em> là ước lượng tham số phù hợp nhất cho <span class="math notranslate nohighlight">\(k\)</span> cụm thông qua phương pháp ước lượng hợp lý tối đa mà chúng ta sẽ thảo luận kĩ hơn ở bên dưới. Một số giả định của mô hình <em>GMM</em>:</p>
<ul class="simple">
<li><p>Có <span class="math notranslate nohighlight">\(k\)</span> cụm cần phân chia mà mỗi cụm tuân theo <em>phân phối Gaussian đa chiều</em> với tập tham số đặc trưng <span class="math notranslate nohighlight">\(\{{(\mu_i, \mathbf{\Sigma}_i)}\}_{i=1}^{k}\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(z_{k}\)</span> được giả định là một biến ngẫu nhiên nhận giá trị 1 nếu như quan sát <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> rơi vào cụm thứ <span class="math notranslate nohighlight">\(k\)</span>, các trường hợp còn lại nhận giá trị 0.</p></li>
<li><p><span class="math notranslate nohighlight">\(z_{k}\)</span> được coi như là một <em>biến ẩn</em> (<em>latent variable</em> hoặc <em>hidden variable</em>) mà ta chưa biết giá trị của nó. Xác suất xảy ra của <span class="math notranslate nohighlight">\(p(z_{k}=1 | \mathbf{x})\)</span> giúp chúng ta xác định tham số phân phối của <em>Gaussian Mixture</em>. Điều này sẽ được thảo luận kĩ hơn bên dưới.</p></li>
</ul>
<p>Tập hợp các giá trị của <span class="math notranslate nohighlight">\(z_{k}\)</span> đối với các cụm sẽ tạo thành một phân phối xác suất sẽ tạo thành một phân phối xác suất <span class="math notranslate nohighlight">\((\pi_1, \pi_2, \dots, \pi_k)\)</span> trong đó <span class="math notranslate nohighlight">\(\pi_k = p(z_{k}=1 | \mathbf{x})\)</span>.</p>
<p>Một xác suất hỗn hợp tại một điểm dữ liệu <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> sẽ được tính theo công thức Bayes như sau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}p(\mathbf{x}) &amp; = &amp; \sum_{c=1}^{k}p(z_c)p(\mathbf{x}|z_c)\\
&amp; = &amp; \sum_{c=1}^{k} p(z_c=1) p(\mathbf{x}|\mu_c, \mathbf{\Sigma}_c) \\
&amp; = &amp; \sum_{c=1}^{k} \pi_c p(\mathbf{x}|\mu_c, \mathbf{\Sigma}_c) \\
&amp; = &amp; \sum_{c=1}^{k} \pi_c N(\mathbf{x}|\mu_c, \mathbf{\Sigma}_c) 
\end{eqnarray}\end{split}\]</div>
<p>Thành phần xác suất <span class="math notranslate nohighlight">\(p(\mathbf{x}|\mu_i, \mathbf{\Sigma}_i)\)</span> được tính từ phân phối <em>Guassian đa chiều</em> và chúng đồng thời là mục tiêu mà chúng ta cần tham số hoá.</p>
<div class="section" id="uoc-luong-hop-ly-toi-da">
<h2>16.2.1. Ước lượng hợp lý tối đa<a class="headerlink" href="#uoc-luong-hop-ly-toi-da" title="Permalink to this headline">¶</a></h2>
<p>Bài toán đặt ra đó là giả sử chúng ta có một tập dữ liệu <span class="math notranslate nohighlight">\(\mathcal{X} = \{\mathbf{x}_i\}_{i=1}^{N}\)</span> hãy tìm ra ước lượng hợp lý tối đa của các tham số <span class="math notranslate nohighlight">\(\theta\)</span> sao cho lớp mô hình được giả định là <em>GMM</em> khớp nhất bộ dữ liệu. Như vậy <span class="math notranslate nohighlight">\(\theta^{*}\)</span> chính là nghiệm của bài toán:</p>
<div class="math notranslate nohighlight">
\[\theta^{*} = \arg \max_{\theta} p(\mathbf{X}|\theta) = \arg \max_{\theta} \prod_{i=1}^{N} p(\mathbf{x}_i| \theta)\]</div>
<p>Để giải phương trình trên chúng ta có thể dựa trên hai cách tiếp cận:</p>
<ul class="simple">
<li><p>Giải trực tiếp phương trình đạo hàm của hàm logarith để theo các hệ số để tìm ra nghiệm tối ưu như đã thực hiện đối với <em>phân phối Gaussian đa biến</em> cho 1 cụm. Tuy nhiên phương pháp này tỏ ra bất khả thi bởi đối với bài toán có nhiều cụm thì hàm mất mát trở nên phức tạp hơn nhiều. Việc giải phương trình đạo hàm dường như là không thể.</p></li>
<li><p>Sử dụng thuật toán <em>EM (Expectation-Maximization)</em> để cập nhật dần dần nghiệm của <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
</ul>
<p>Thuật toán <em>EM</em> là một trong những phương pháp thường được sử dụng để cập nhật nghiệm theo hàm hợp lý. Đây là một phương pháp đơn giản và hiệu quả, phù hợp với các bài toán phức tạp khi mà lời giải trực tiếp từ đạo hàm không dễ dàng tìm kiếm. Bên dưới chúng ta sẽ tiếp tục tìm hiểu phương pháp này:</p>
<p>Trong thuật toán <em>EM</em> chúng ta liên tục thực hiện các vòng lặp mà mỗi vòng lặp bao gồm hai bước huấn luyện chính:</p>
<ul class="simple">
<li><p>E-Step: Ước lượng phân phối của <em>biến ẩn</em> <span class="math notranslate nohighlight">\(z\)</span> thể hiện phân phối xác suất của các cụm tương ứng với dữ liệu và bộ tham số phân phối.</p></li>
<li><p>M-Step: Tối đa hoá phân phối xác suất đồng thời (<em>join distribution probability</em>) của dữ liệu và <em>biến ẩn</em>.</p></li>
</ul>
<p>Cụ thể những bước này sẽ được thể hiện qua hình minh hoạ:</p>
<p><img alt="" src="https://imgur.com/NNCFeR1.png" /></p>
<p><strong>Hình 4</strong>: Hình bên trái là bước E-Step. Tại bước này chúng ta tính toán phân phối xác suất tại từng điểm dữ liệu ứng với mỗi cụm theo bộ tham số phân phối trên từng cụm lúc ban đầu. Chẳng hạn tại một điểm trong hình ở phía trên chúng ta tính ra hai xác suất là <span class="math notranslate nohighlight">\(P(A)=0.6\)</span> và <span class="math notranslate nohighlight">\(P(B)=0.4\)</span> và tại một điểm ở phía dưới tính ra xác suất <span class="math notranslate nohighlight">\(P(A)=0.2\)</span> và <span class="math notranslate nohighlight">\(P(B)=0.8\)</span>. Tiếp theo hình bên phải là bước M-Step thể hiện cách cập nhật lại tham số để phù hợp với phân phối của các cụm dữ liệu. Ở đây tham số trung bình của các cụm được cập nhật lại đồng nghĩa với việc dịch chuyển cụm sao cho giá trị hợp lý của phân phối lý thuyết được tối đa hoá và tiến gần tới phân phối thực ở mỗi cụm.</p>
<p>Để cập nhật tham số thì chúng ta xét một hàm <em>auxilary</em> như sau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}Q(\theta, \theta_t) &amp; = &amp; \mathbb{E}_{z}(\log p(\mathbf{X}, \mathbf{Z} | \theta_t)) \\
&amp; = &amp; \sum_z p(z|\mathbf{X}, \theta_t) \log p(\mathbf{X}, \mathbf{Z} | \theta) \\
&amp; = &amp; \sum_z p(z|\mathbf{X}, \theta_t) \log \left[~ p(\mathbf{Z} | \mathbf{X}, \theta) p(\mathbf{X} | \theta) \right] \\
&amp; = &amp; \sum_z p(z|\mathbf{X}, \theta_t) \log p(\mathbf{Z} | \mathbf{X}, \theta) + \underbrace{\left[ \sum_z p(z|\mathbf{X}, \theta) \right]}_{1} \log p(\mathbf{X} | \theta) \\
&amp; = &amp; \sum_z p(z|\mathbf{X}, \theta_t) \log p(\mathbf{Z} | \mathbf{X}, \theta) + \log p(\mathbf{X} | \theta)
\end{eqnarray}\end{split}\]</div>
<p>Như vậy <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span> chính là kì vọng của logarith xác suất chung của <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> và <span class="math notranslate nohighlight">\(\mathbf{Z}\)</span> trên từng cụm dữ liệu. Giá trị kì vọng này bằng tổng theo trọng số của xác suất tiên nghiệm <span class="math notranslate nohighlight">\(p(z|\mathbf{X}, \theta_t)\)</span> trên từng cụm. Xác suất này có thể tính được dựa trên tham số <span class="math notranslate nohighlight">\(\theta_t\)</span> trước đó (<span class="math notranslate nohighlight">\(\theta\)</span> ở đây là đại diện chung cho cả <span class="math notranslate nohighlight">\(\mu\)</span> và <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>). Tham số mà chúng ta cần cập nhật sẽ nằm ở <em>log likehood</em> của xác suất chung <span class="math notranslate nohighlight">\(\log p(\mathbf{X}, \mathbf{Z} | \theta) \)</span>. Để tính xác suất này chúng ta phân tích chúng theo công thức Bayes giữa <span class="math notranslate nohighlight">\(p(\mathbf{Z} | \mathbf{X}, \theta)\)</span> và <span class="math notranslate nohighlight">\(p(\mathbf{X} | \theta)\)</span>. Cuối cùng chúng ta rút gọn thành tổng giữa logarith hàm hợp lý <span class="math notranslate nohighlight">\(\log p(\mathbf{X} | \theta)\)</span> và logarith xác suất hậu nghiệm <span class="math notranslate nohighlight">\(\log p(\mathbf{Z} | \mathbf{X}, \theta)\)</span>.</p>
<p>Tại sao tối đa hoá hàm hợp lý chúng ta lại thông qua <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span>. Đó là bởi khi giá trị <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span> gia tăng thì kéo theo sự gia tăng <em>hàm hợp lý</em>. Như vậy tồn tại một chuỗi vô hạn <span class="math notranslate nohighlight">\(\{\theta_j'\}_{j=0}^{\infty}\)</span> sao cho <span class="math notranslate nohighlight">\(Q(\theta_j', \theta_t)\)</span> là một chuỗi tăng và dẫn tới <span class="math notranslate nohighlight">\(\{\theta_j'\}_{j=0}^{\infty}\)</span> hội tụ về nghiệm cực đại <span class="math notranslate nohighlight">\(\theta^{*}\)</span>. Khi đó giá trị <em>hàm hợp lý</em> <span class="math notranslate nohighlight">\(\log p(\mathbf{X} | \theta')\)</span> cũng là một chuỗi tăng và có nghiệm hội tụ về <span class="math notranslate nohighlight">\(\theta^*\)</span>. Tức là quá trình tìm nghiệm của <em>hàm hợp lý</em> có thể tìm được thông qua hàm <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span>.</p>
<p>Tiếp theo ta sẽ chứng minh rằng sự gia tăng của <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span> kéo theo sự gia tăng của <em>hàm hợp lý</em>. Thật vậy:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}Q(\theta, \theta_t) - Q(\theta_t, \theta_t) &amp; = &amp; \log p(\mathbf{X} | \theta) - \log p(\mathbf{X} | \theta_t) - \sum_z p(z|\mathbf{X}, \theta_t) \log \frac{p(\mathbf{Z} | \mathbf{X}, \theta)}{p(\mathbf{Z} | \mathbf{X}, \theta_t)} \\
&amp; = &amp; \log p(\mathbf{X} | \theta) - \log p(\mathbf{X} | \theta_t) - \underbrace{\text{KL}(p(\mathbf{Z} | \mathbf{X}, \theta), p(\mathbf{Z} | \mathbf{X}, \theta_t))}_{\geq 0} \\
&amp; \leq &amp;  \log p(\mathbf{X} | \theta) - \log p(\mathbf{X} | \theta_t)
\end{eqnarray}\end{split}\]</div>
<p>Dòng thứ 2 được suy ra là bởi <span class="math notranslate nohighlight">\(\sum_z p(z|\mathbf{X}, \theta_t) \log \frac{p(\mathbf{Z} | \mathbf{X}, \theta)}{p(\mathbf{Z} | \mathbf{X}, \theta_t)}\)</span> chính là một độ đo Kullback-Leibler Divergence về khoảng cách giữa hai phân phối. Giá trị này luôn lớn hơn hoặc bằng 0. Bạn có thể xem thêm chứng minh tại <a class="reference external" href="https://phamdinhkhanh.github.io/2020/07/25/GAN_Wasserstein.html#3-kullback-leibler-divergence">Kullback-Leibler Divergence</a>.</p>
<p>Bất đẳng thức trên cho thấy khi <span class="math notranslate nohighlight">\(Q(\theta, \theta_t) \geq Q(\theta_t, \theta_t)\)</span> sẽ kéo theo <span class="math notranslate nohighlight">\(\log p(\mathbf{X} | \theta) \geq \log p(\mathbf{X} | \theta_t)\)</span>. Như vậy thay vì tối đa hoá hàm mục tiêu là <em>hàm hợp lý</em> thì chúng ta có thể tối đa hoá hàm <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span>.</p>
</div>
<div class="section" id="khai-trien-ham-auxilary">
<h2>16.2.2. Khai triển hàm <em>auxilary</em><a class="headerlink" href="#khai-trien-ham-auxilary" title="Permalink to this headline">¶</a></h2>
<p>Xác suất xảy ra tại một điểm dữ liệu có thể được biểu diễn theo <a class="reference external" href="https://phamdinhkhanh.github.io/deepai-book/ch_probability/appendix_probability.html#phan-phoi-category">phân phối Category</a> như sau:</p>
<div class="math notranslate nohighlight">
\[p(\mathbf{x}_i, \mathbf{z} | \theta) = \prod_{j=1}^{k} [p(\mathbf{x}_i, z_{j}| \theta)]^{z_{j}}  = \prod_{j=1}^{k} [p(\mathbf{x}_i | z_{j}, \theta) p(z_{j} | \theta)]^{z_{j}} = \prod_{j=1}^{k} [p(\mathbf{x}_i | z_{j}, \theta) \pi_j]^{z_{j}}\]</div>
<p>Như vậy giá trị hàm hợp lý của phân phối xác suất đồng thời có thể được viết như sau:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\mathbf{X}, \mathbf{Z} | \theta) = p(\mathbf{X}, \mathbf{Z} | \theta) = \prod_{i=1}^{N}\prod_{j=1}^{k} \left[ p(\mathbf{x}_i, z_{j} | \theta) \right]^{z_{j}} = \prod_{i=1}^{N}\prod_{j=1}^{k} \left[ p(\mathbf{x}_i | z_{j}, \theta)\pi_j \right]^{z_{j}}\]</div>
<p>Lấy logarith hai vế ta thu được:</p>
<div class="math notranslate nohighlight">
\[\log[p(\mathbf{X}, \mathbf{Z})] = \sum_{i=1}^{N} \sum_{j=1}^{k} z_{j} \log p(\mathbf{x}_i | z_{j}, \theta) + z_{j} \log \pi_j\]</div>
<p>Như vậy:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}Q(\theta, \theta_t) &amp; = &amp; \mathbb{E}_{z} \left[ \log p(\mathbf{X}, \mathbf{Z})| \theta_t \right] \\
&amp; = &amp; \mathbb{E}_{z} \left[ \sum_{i=1}^{N} \sum_{j=1}^{k} z_{j} \log p(\mathbf{x}_i | z_{j}, \theta) + z_{j} \log \pi_j | \theta_t \right] \\
&amp; = &amp;  \sum_{i=1}^{N} \sum_{j=1}^{k} \mathbb{E}_{z} [ z_{j}|\theta_t] \log p(\mathbf{x}_i | z_{j}, \theta) + \mathbb{E}_{z} [z_{j} | \theta_t] \log \pi_j \\
&amp; = &amp; \sum_{i=1}^{N} \sum_{j=1}^{k} p(z_{j} | \mathbf{x}_i , \theta_t) \left[ \log p(\mathbf{x}_i | z_{j}, \theta) + \log \pi_j \right] \\
&amp; = &amp; \sum_{i=1}^{N}\sum_{j=1}^{k} p( z_{j} | \mathbf{x}_i , \theta_t)  \left[  \log \frac{\exp \left( - \frac{1}{2} (\mathbf{x}_{i} - \mu_j)^{\intercal} \mathbf{\Sigma}_j^{-1} (\mathbf{x}_{i} - \mu_j) \right)}{(2 \pi)^{d/2} |\mathbf{\Sigma}_j|^{1/2}} + \log \pi_j \right] \\
&amp; = &amp; \sum_{i=1}^{N}\sum_{j=1}^{k} p( z_{j} | \mathbf{x}_i , \theta_t) \left[ - \frac{1}{2} \log |\mathbf{\Sigma}_j| - \frac{1}{2}   \mathbf{(x}_{i} - \mu_j)^{\intercal} \mathbf{\Sigma}_j^{-1} (\mathbf{x}_{i} - \mu_j) + \log \pi_j+  C_j  \right]
\end{eqnarray}\end{split}\]</div>
</div>
<div class="section" id="cac-buoc-trong-gmm">
<h2>16.2.3. Các bước trong GMM<a class="headerlink" href="#cac-buoc-trong-gmm" title="Permalink to this headline">¶</a></h2>
<p><strong>Bước E-Step</strong>:</p>
<p>Mục tiêu của bước E-Step là tính xác suất của mỗi điểm dữ liệu dựa vào <em>phân phối Gaussian đa chiều</em> dựa trên tham số <span class="math notranslate nohighlight">\(\theta_t\)</span> của vòng lặp gần nhất. Xác suất này được tính như sau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\mathbb{E}_{z}(z_{j} | \mathbf{x}_i, \theta_t) &amp; = &amp; 1 \times p(z_{j} = 1 |  \mathbf{x}_i, \theta_t) + 0 \times p(z_{j} = 0 |  \mathbf{x}_i,\theta_t) \\
&amp; = &amp; p(z_{j}|\mathbf{x}_i, \theta_t) \\
&amp; = &amp; \frac{p(z_{j} | \theta_t) p(\mathbf{x}_i | z_{j}, \theta_t)}{p(\mathbf{x}_i | \theta_t)} \\
&amp; = &amp; \frac{\pi_j N(\mu_{jt}, \mathbf{\Sigma}_{jt}|\mathbf{x}_i)}{\sum_{j} \pi_j N(\mu_{jt}, \mathbf{\Sigma}_{jt}|\mathbf{x}_i)}
\end{eqnarray}\end{split}\]</div>
<p>Xác suất <span class="math notranslate nohighlight">\(\pi_j\)</span> chính là <em>xác suất tiên nghiệm</em> (<em>posteriori probability</em>) bằng với tỷ lệ các quan sát thuộc về cụm <span class="math notranslate nohighlight">\(j\)</span> ở vòng lặp thứ <span class="math notranslate nohighlight">\(t\)</span>. Trong khi <span class="math notranslate nohighlight">\(N(\mu_{jt}, \mathbf{\Sigma}_{jt}|\mathbf{x}_i)\)</span> là xác suất của <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> rơi vào cụm thứ <span class="math notranslate nohighlight">\(j\)</span> được tính theo <em>phân phối Gaussian đa chiều</em>. Hai xác suất này có thể tính được và sau cùng ta thu được xác suất rơi vào mỗi cụm tại mỗi một quan sát <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span>.</p>
<p><strong>Bước M-Step</strong>:</p>
<p>Tại bước M-Step chúng ta cần cập nhật lại tham số phân phối theo hàm <em>auxiliary</em> <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span>. Cực trị đạt được khi đạo hàm bậc nhất bằng 0:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial Q(\theta, \theta_t)}{\partial \theta} = 0\]</div>
<p>Ở đây <span class="math notranslate nohighlight">\(\theta\)</span> là các tham số <span class="math notranslate nohighlight">\(\{\pi_j, \mu_j, \mathbf{\Sigma}_j \}_{j=1}^k\)</span>. Lần lượt giải phương trình đạo hàm theo <span class="math notranslate nohighlight">\(\mu_j\)</span> và <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_j\)</span> tương tự như đối với ước lượng MLE đã trình bày ở chương thứ hai:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\frac{\partial Q(\theta, \theta_t)}{\partial \mu_j} &amp; = &amp;  \frac{\partial}{\partial \mu_j} \sum_{i=1}^{N}\sum_{j=1}^{k} p( z_{j} | \mathbf{x}_i , \theta_t) \left[ - \frac{1}{2} \log |\mathbf{\Sigma}_j| - \frac{1}{2}   \mathbf{(x}_{i} - \mu_j)^{\intercal} \mathbf{\Sigma}_j^{-1} (\mathbf{x}_{i} - \mu_j) + \log \pi_j+  C_j  \right] \\
&amp; = &amp; \frac{\partial}{\partial \mu_j} p( z_{j} | \mathbf{x}_i , \theta_t) \left[ \sum_{i=1}^N  \mathbf{\Sigma}_j^{-1} (\mu_j-\mathbf{x}_{i})  \right] \\
&amp; = &amp; \frac{\partial}{\partial \mu_j} \mathbf{\Sigma}_j^{-1} \left[ \sum_{i=1}^N  p( z_{j} | \mathbf{x}_i , \theta_t) (\mu_j-\mathbf{x}_{i})  \right] \\
&amp; = &amp; 0
\end{eqnarray}\end{split}\]</div>
<p>Từ đó suy ra:</p>
<div class="math notranslate nohighlight">
\[\mu_j^{*} = \frac{\sum_{i=1}^{N} p(z_j| \mathbf{x}_i, \theta_t) \mathbf{x}_i}{\sum_{i=1}^N p(z_j | \mathbf{x}_i, \theta_t)}\]</div>
<p>Trong đó <span class="math notranslate nohighlight">\(p(z_j| \mathbf{x}_i, \theta_t)\)</span> chính là xác suất tương ứng để <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> thuộc về cụm <span class="math notranslate nohighlight">\(j\)</span> được tính từ bước E-Step.</p>
<p>Tiếp theo ta cần tính đạo hàm theo <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_j\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\frac{\partial Q(\theta, \theta_t)}{\partial \mathbf{\Sigma}_j^{-1}} &amp; = &amp;  \frac{\partial}{\partial \mu_j} \sum_{i=1}^{N}\sum_{j=1}^{k} p( z_{j} | \mathbf{x}_i , \theta_t) \left[ - \frac{1}{2} \log |\mathbf{\Sigma}_j| - \frac{1}{2}   \mathbf{(x}_{i} - \mu_j)^{\intercal} \mathbf{\Sigma}_j^{-1} (\mathbf{x}_{i} - \mu_j) + \log \pi_j+  C_j  \right] \\
&amp; = &amp; \sum_{i=1}^{N}p( z_{j} | \mathbf{x}_i , \theta_t) \left[ \frac{1}{2}\mathbf{\Sigma}_j - \frac{1}{2}  (\mathbf{x}_{i} - \mu_j) (\mathbf{x}_{i} - \mu_j)^{\intercal} \right] \\
&amp; = &amp; 0
\end{eqnarray}\end{split}\]</div>
<p>Suy ra:</p>
<div class="math notranslate nohighlight">
\[\mathbf{\Sigma}_j^{*} = \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t) [(\mathbf{x}_i-\mu_j)(\mathbf{x}_i-\mu_j)^{\intercal}]}{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t)}\]</div>
<p>Như vậy tham số tối ưu ở mỗi cụm sẽ được cập nhật theo công thức:</p>
<div class="math notranslate nohighlight">
\[\mu_j^* = \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t) \mathbf{x}_i}{\sum_{i=1}^{N} p(z_{j}| \mathbf{x}_i, \theta_t)}\]</div>
<div class="math notranslate nohighlight">
\[\mathbf{\Sigma}_j^* = \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t) [(\mathbf{x}_i-\mu_j)(\mathbf{x}_i-\mu_j)^{\intercal}]}{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t)}\]</div>
<p>Để tính <span class="math notranslate nohighlight">\(\pi_j\)</span> chúng ta dựa vào điều kiện ràng buộc <span class="math notranslate nohighlight">\(\sum_{j=1}^k \pi_j=1\)</span>. Khi đó hàm Lagrange tương ứng với <span class="math notranslate nohighlight">\(Q(\theta, \theta_t)\)</span> là:</p>
<div class="math notranslate nohighlight">
\[J(\theta, \theta_t) = Q(\theta, \theta_t) + \lambda(1 - \sum_{j=1}^{k} \pi_j)\]</div>
<p>Do đó:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\frac{\partial J(\theta, \theta_t)}{\partial \pi_j} &amp; = &amp; \frac{\partial Q(\theta, \theta_t)}{\partial \pi_j} - \lambda \\
&amp; = &amp; \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t)}{\pi_j} - \lambda = 0
\end{eqnarray}\end{split}\]</div>
<p>Từ đó suy ra:</p>
<div class="math notranslate nohighlight">
\[\pi_j = \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t)}{\lambda} \tag{1}\]</div>
<p>Mặt khác ta có <span class="math notranslate nohighlight">\(\sum_{j=1}^{k} \pi_j = 1\)</span>. Do đó:</p>
<div class="math notranslate nohighlight">
\[\sum_{j=1}^k \pi_j = \frac{\sum_{i=1}^{N} \sum_{j=1}^k p(z_{j} | \mathbf{x}_i, \theta_t)}{\lambda} = \frac{N}{\lambda} = 1\]</div>
<p>Suy ra <span class="math notranslate nohighlight">\(\lambda = N\)</span> và thế vào công thức <span class="math notranslate nohighlight">\((1)\)</span> ta được:</p>
<div class="math notranslate nohighlight">
\[\pi_j^* = \frac{\sum_{i=1}^{N} p(z_{j} | \mathbf{x}_i, \theta_t)}{N}\]</div>
<p>Như vậy chúng ta đã tìm ra được tham số tối ưu của thuật toán <em>GMM</em> sau mỗi vòng lặp. Việc giải trực tiếp bài toán tối ưu <em>hàm hợp lý</em> theo ước lượng <em>MLE</em> là bất khả thi trong điều kiện có nhiều cụm dữ liệu. Chính vì thế thuật toán <em>EM</em> được áp dụng để cập nhật dần dần tham số của mô hình. Thuật toán sẽ dần dần hội tụ sau một hữu hạn bước. Về lý thuyết của thuật toán <em>GMM</em> chúng ta sẽ phải trải qua nhiều tính toán đạo hàm tương đối phức tạp. Tuy nhiên để thực hành thuật toán này lại tương đối dễ dàng trong sklearn. Chúng ta cùng sang phần thực hành để nắm rõ chi tiết.</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="thuc-hanh-mo-hinh">
<h1>16.4. Thực hành mô hình<a class="headerlink" href="#thuc-hanh-mo-hinh" title="Permalink to this headline">¶</a></h1>
<p>Đầu tiên chúng ta sẽ import các package cần thiết cho quá trình tiền xử lý dữ liệu, huấn luyện và biểu đồ hoá kết quả.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">linalg</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.patheffects</span> <span class="k">as</span> <span class="nn">PathEffects</span>
<span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Ellipse</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="tien-xu-ly-du-lieu">
<h2>16.4.1. Tiền xử lý dữ liệu<a class="headerlink" href="#tien-xu-ly-du-lieu" title="Permalink to this headline">¶</a></h2>
<p>Để tiện so sánh hiệu quả giữa các thuật toán phân cụm trong học không giám sát. Bộ dữ liệu được sử dụng chung là <a class="reference external" href="https://raw.githubusercontent.com/phamdinhkhanh/datasets/cf391fa1a7babe490fdd10c088f0ca1b6d377f59/shopping-data.csv">shopping-data</a>. Bộ dữ liệu này bao gồm các trường thông tin như <code class="docutils literal notranslate"><span class="pre">giới</span> <span class="pre">tính,</span> <span class="pre">độ</span> <span class="pre">tuổi,</span> <span class="pre">thu</span> <span class="pre">nhập</span> <span class="pre">hàng</span> <span class="pre">năm</span> <span class="pre">và</span> <span class="pre">điểm</span> <span class="pre">số</span> <span class="pre">mua</span> <span class="pre">sắm</span></code> nhằm mô tả hành vi mua sắm của những khách hàng. Mục tiêu của chúng ta đó là phân cụm khác hàng thành những nhóm dựa trên hành vi mua sắm đặc trưng của họ.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/phamdinhkhanh/datasets/cf391fa1a7babe490fdd10c088f0ca1b6d377f59/shopping-data.csv&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(200, 4)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Genre</th>
      <th>Age</th>
      <th>Annual Income (k$)</th>
      <th>Spending Score (1-100)</th>
    </tr>
    <tr>
      <th>CustomerID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Male</td>
      <td>19</td>
      <td>15</td>
      <td>39</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Male</td>
      <td>21</td>
      <td>15</td>
      <td>81</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Female</td>
      <td>20</td>
      <td>16</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Female</td>
      <td>23</td>
      <td>16</td>
      <td>77</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Female</td>
      <td>31</td>
      <td>17</td>
      <td>40</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Để đơn giản hoá chúng ta chỉ cần sử dụng hai trường thông tin đầu vào là thu nhập và điểm shopping. Để thuật toán không bị ảnh hưởng bởi sự khác biệt về đơn vị thì chúng ta cần chuẩn hoá theo <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code>. Bạn đọc cũng có thể lựa chọn những phương pháp chuẩn hoá dữ liệu khác. Xem thêm <a class="reference external" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/FeatureEngineering.html#id2">các phương pháp chuẩn hoá dữ liệu</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Lấy ra thu nhập va điểm shopping</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Chuẩn hoá dữ liệu</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_std</span> <span class="o">=</span> <span class="n">std</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_std</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(200, 2)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="mo-hinh-gaussian-mixture">
<h2>16.4.2. Mô hình <em>Gaussian Mixture</em><a class="headerlink" href="#mo-hinh-gaussian-mixture" title="Permalink to this headline">¶</a></h2>
<p>Để xây dựng mô hình <em>Gaussian Mixture</em> trên sklearn chúng ta sử dụng class <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture.fit">sklearn.mixture.GaussianMixture</a>. Class này có ý nghĩa như sau:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> 
  <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span> 
  <span class="n">tol</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> 
  <span class="n">reg_covar</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> 
  <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
  <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
  <span class="n">init_params</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span>
  <span class="o">...</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Trong đó:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_components</span></code>: Là số lượng cụm mà chúng ta cần phân chia.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">covariance_type</span></code>: Định dạng covariance được sử dụng trong thuật toán <em>GMM</em>. Trong đó bao gồm: <code class="docutils literal notranslate"><span class="pre">{'full',</span> <span class="pre">'tied',</span> <span class="pre">'diag',</span> <span class="pre">'spherical'}</span></code>. Lựa chọn ‘full’ mặc định có nghĩa rằng mỗi một thành phần cụm có một ma trận hiệp phương sai riêng. ‘tied’ được lựa chọn khi chúng ta muốn đồng nhất ma trận hiệp phương sai giữa các cụm. ‘diag’ tương ứng với ma trận hiệp phương sai là ma trận đường chéo và khi lựa chọn ‘spherical’ có nghĩa rằng mỗi một thành phần cụm sẽ có một phương sai riêng.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tol</span></code>: Ngưỡng hội tụ của thuật toán <em>EM</em>. Nếu mức độ cải thiện của hàm mục tiếu thấp hơn ngưỡng này thì mô hình sẽ dừng.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_iter</span></code>: Số lượng vòng lặp tối đa của thuật toán <em>EM</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">init_params</span></code>: Lựa chọn khởi tạo tham số cho mô hình lúc ban đầu. Mặc định mô hình sẽ sử dụng khởi tạo từ thuật toán k-Means clustering. Như vậy sau mỗi vòng lặp thì thuật toán sẽ sửa lỗi của k-Means và tạo ra một kết quả với mức độ hợp lý cao hơn so với k-Means.</p></li>
</ul>
<p>Bên dưới chúng ta cùng tạo ra mô hình <em>GMM</em> với số lượng cụm cần phân chia là 5. Sau huấn luyện thì trung bình và ma trận hiệp phương sai của mỗi cụm có thể thu được thông qua hai thuộc tính là <em>means</em>_ và <em>covariances</em>_.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                     <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span> 
                     <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_std</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;means: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">gm</span><span class="o">.</span><span class="n">means_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;covariances: </span><span class="se">\n</span><span class="s1"> &#39;</span><span class="p">,</span> <span class="n">gm</span><span class="o">.</span><span class="n">covariances_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>means: 
 [[0.60502531 0.15433196]
 [0.33368985 0.49394756]
 [0.58393969 0.82673863]
 [0.0829305  0.80743088]
 [0.09861098 0.21597752]]
covariances: 
  [[[ 0.01818446  0.00433814]
  [ 0.00433814  0.00873064]]

 [[ 0.00613567 -0.00231927]
  [-0.00231927  0.0051635 ]]

 [[ 0.01808598 -0.00031096]
  [-0.00031096  0.0091568 ]]

 [[ 0.00337483 -0.0001437 ]
  [-0.0001437   0.01026088]]

 [[ 0.00453005  0.00255303]
  [ 0.00255303  0.01918353]]]
</pre></div>
</div>
</div>
</div>
<p>Chúng ta nhận thấy rằng các tâm của các cụm cách xa nhau nên khả năng thuật toán sẽ mang lại kết quả tốt với số cụm <span class="math notranslate nohighlight">\(k=5\)</span>. Ma trận hiệp phương sai là những ma trận vuông đối xứng.</p>
</div>
<div class="section" id="lua-chon-sieu-tham-so-cho-mo-hinh-gmm">
<h2>16.4.3. Lựa chọn siêu tham số cho mô hình <em>GMM</em><a class="headerlink" href="#lua-chon-sieu-tham-so-cho-mo-hinh-gmm" title="Permalink to this headline">¶</a></h2>
<p>Để lựa chọn siêu tham số cho mô hình <em>GMM</em> chúng ta sẽ dựa trên mức độ phù hợp được đánh giá thông qua chỉ số <a class="reference external" href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">BIC (Bayesian Information Criteria)</a>. Đây là chỉ số đo lường mức độ hợp lý của mô hình đối với một bộ tham số được tính dựa trên giá trị tối đa của <em>hàm hợp lý</em> như sau:</p>
<div class="math notranslate nohighlight">
\[\text{BIC} = k \ln(n) - 2 \ln (\hat{L})\]</div>
<p>Với <span class="math notranslate nohighlight">\(k\)</span> là số lượng tham số được ước lượng từ mô hình, <span class="math notranslate nohighlight">\(n\)</span> là số lượng quan sát của bộ dữ liệu và <span class="math notranslate nohighlight">\(\hat{L}\)</span> là giá trị ước lượng tối đa của <em>hàm hợp lý</em>. Chỉ số <em>BIC</em> là một trong những giá trị quan trọng thường được sử dụng để đánh giá và lựa chọn các mô hình khác nhau. Mô hình có <em>BIC</em> càng nhỏ thì mức độ hợp lý của mô hình đối với bộ dữ liệu càng cao. Chúng ta sẽ huấn luyện mô hình <em>GMM</em> với nhiều tham số <code class="docutils literal notranslate"><span class="pre">n_components</span></code> và tìm ra giá trị có BIC là nhỏ nhất. Đó chính là số lượng thành phần phù hợp nhất của bộ dữ liệu được tính theo mô hình <em>GMM</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lowest_bic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">infty</span>
<span class="n">bic</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">n_components_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="c1"># cv_types = [&#39;spherical&#39;, &#39;tied&#39;, &#39;diag&#39;, &#39;full&#39;]</span>
<span class="n">cv_types</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">,</span> <span class="s1">&#39;tied&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">cv_type</span> <span class="ow">in</span> <span class="n">cv_types</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">n_components</span> <span class="ow">in</span> <span class="n">n_components_range</span><span class="p">:</span>
        <span class="c1"># Fit Gaussian mixture theo phương pháp huấn luyện EM</span>
        <span class="n">gmm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span>
                                      <span class="n">covariance_type</span><span class="o">=</span><span class="n">cv_type</span><span class="p">)</span>
        <span class="n">gmm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_std</span><span class="p">)</span>
        <span class="n">bic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">bic</span><span class="p">(</span><span class="n">X_std</span><span class="p">))</span>
        <span class="c1"># Gán model có BIC scores thấp nhất là model tốt nhất</span>
        <span class="k">if</span> <span class="n">bic</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">lowest_bic</span><span class="p">:</span>
            <span class="n">lowest_bic</span> <span class="o">=</span> <span class="n">bic</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">best_gmm</span> <span class="o">=</span> <span class="n">gmm</span>

<span class="n">bic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">bic</span><span class="p">)</span>
<span class="n">color_iter</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">cycle</span><span class="p">([</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="s1">&#39;turquoise&#39;</span><span class="p">])</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">best_gmm</span>
<span class="n">bars</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Vẽ biểu đồ BIC scores</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">cv_type</span><span class="p">,</span> <span class="n">color</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">cv_types</span><span class="p">,</span> <span class="n">color_iter</span><span class="p">)):</span>
    <span class="n">xpos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">)</span> <span class="o">+</span> <span class="mf">.2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">bars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">xpos</span><span class="p">,</span> <span class="n">bic</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">):</span>
                                  <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">)],</span>
                        <span class="n">width</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="n">bic</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.01</span> <span class="o">-</span> <span class="mf">.01</span> <span class="o">*</span> <span class="n">bic</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">bic</span><span class="o">.</span><span class="n">max</span><span class="p">()])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;BIC score per model&#39;</span><span class="p">)</span>
<span class="n">xpos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">bic</span><span class="o">.</span><span class="n">argmin</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">))</span> <span class="o">+</span> <span class="mf">.65</span> <span class="o">+</span>\
    <span class="mf">.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">bic</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_components_range</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">xpos</span><span class="p">,</span> <span class="n">bic</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.97</span> <span class="o">+</span> <span class="mf">.03</span> <span class="o">*</span> <span class="n">bic</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">bars</span><span class="p">],</span> <span class="n">cv_types</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7f10642bc250&gt;
</pre></div>
</div>
<img alt="../_images/GMM_24_1.png" src="../_images/GMM_24_1.png" />
</div>
</div>
<p>Như vậy ta có thể nhận thấy mô hình phù hợp nhất là mô hình có <code class="docutils literal notranslate"><span class="pre">n_components</span> <span class="pre">=</span> <span class="pre">6</span></code> và dạng <code class="docutils literal notranslate"><span class="pre">covariance_type</span></code> được sử dụng là <code class="docutils literal notranslate"><span class="pre">tied</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_gmm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GaussianMixture(covariance_type=&#39;tied&#39;, n_components=6)
</pre></div>
</div>
</div>
</div>
<p>Tiếp theo chúng ta sẽ dự báo cụm và vẽ biểu đồ các điểm trên không gian 2 chiều.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_plot_kmean_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    X: dữ liệu đầu vào</span>
<span class="sd">    labels: nhãn dự báo</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># lựa chọn màu sắc</span>
    <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
    <span class="n">palette</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;hls&quot;</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>

    <span class="c1"># vẽ biểu đồ scatter</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">()</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">palette</span><span class="p">[</span><span class="n">labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)])</span>

    <span class="c1"># thêm nhãn cho mỗi cluster</span>
    <span class="n">txts</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
        <span class="c1"># Vẽ text tên cụm tại trung vị của mỗi cụm</span>
        <span class="n">xtext</span><span class="p">,</span> <span class="n">ytext</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">txt</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">xtext</span><span class="p">,</span> <span class="n">ytext</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">24</span><span class="p">)</span>
        <span class="n">txt</span><span class="o">.</span><span class="n">set_path_effects</span><span class="p">([</span>
            <span class="n">PathEffects</span><span class="o">.</span><span class="n">Stroke</span><span class="p">(</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">foreground</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">),</span>
            <span class="n">PathEffects</span><span class="o">.</span><span class="n">Normal</span><span class="p">()])</span>
        <span class="n">txts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;t-sne visualization&#39;</span><span class="p">)</span>

<span class="n">labels</span> <span class="o">=</span> <span class="n">best_gmm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_std</span><span class="p">)</span>
<span class="n">_plot_kmean_scatter</span><span class="p">(</span><span class="n">X_std</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GMM_28_0.png" src="../_images/GMM_28_0.png" />
</div>
</div>
<p>Chúng ta nhận thấy rằng thuật toán <em>GMM</em> đưa ra kết quả rất chuẩn xác. Nếu so sánh với các thuật toán khác như <em>k-Means, Hierarchical Clustering, DBSCAN</em> thì kết quả của <em>GMM</em> là chuẩn xác nhất trên bộ dữ liệu shopping-data. Tuy nhiên nhận định này không đúng trong mọi trường hợp đối với mọi bộ dữ liệu nên chúng ta cần phải thử nghiệm nhiều mô hình khác nhau để so sánh.</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="tong-ket">
<h1>16.5. Tổng kết<a class="headerlink" href="#tong-ket" title="Permalink to this headline">¶</a></h1>
<p><em>GMM</em> là một mô hình xác suất. Mô hình này thể hiện sự cải tiến so với <em>k-Means</em> đó là các điểm dữ liệu được sinh ra từ một phân phối hỗn hợp của một số hữu hạn các <em>phân phối Gaussian đa chiều</em>. Tham số của những phân phối này được giả định là chưa biết. Để tìm ra tham số huấn luyện cho các mô hình thì chúng ta sẽ tìm cách tối đa hoá hàm <em>auxiliary</em> thông qua thuật toán <em>EM</em>, thuật toán này sẽ cập nhật nghiệm sau mỗi vòng lặp để đi đến điểm cực trị. Chúng ta có thể coi rằng <em>GMM</em> như là một dạng khái quát của thuật toán <em>k-Means clustering</em> nhằm kết hợp với thông tin về hiệp phương sai của dữ liệu cũng như là tâm của các phân phối <em>Gaussian</em> tiềm ẩn. Cùng tổng kết một số kiến thức mà chương này mang lại:</p>
<ul class="simple">
<li><p><em>Phân phối Guassian đa biến</em> là gì ? Chúng được đặc trưng bởi những tham số nào?</p></li>
<li><p>Phương pháp <em>EM</em> trong huấn luyện <em>hàm hợp lý</em>.</p></li>
<li><p>Xây dựng mô hình <em>GMM</em> trên sklearn.</p></li>
<li><p>Cách thức lựa chọn tham số cho mô hình <em>GMM</em> thông qua chỉ số <em>BIC</em>.</p></li>
</ul>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="bai-tap">
<h1>16.6. Bài tập<a class="headerlink" href="#bai-tap" title="Permalink to this headline">¶</a></h1>
<p>1.- Giả sử một biến <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^{2}\)</span> có <em>phân phối Gaussian đa chiều</em> với trung bình là <span class="math notranslate nohighlight">\(\mu = [1, 1]\)</span> và ma trận hiệp phương sai là ma trận đơn vị <span class="math notranslate nohighlight">\(\mathbf{\Sigma} = \mathbf{I}_2\)</span>. Hãy tính xác suất:</p>
<div class="math notranslate nohighlight">
\[N(\mathbf{x}_i = [0, 0]) | \mu, \mathbf{\Sigma})\]</div>
<p>2.- Ước lượng MLE của <em>phân phối Gaussian đa chiều</em> có kết quả như thế nào?</p>
<p>3.- Trong mô hình <em>GMM</em> thì mỗi một điểm dữ liệu là kết hợp của một hay nhiều phân phối xác suất thành phần?</p>
<p>4.- Thuật toán <em>EM</em> giúp huấn luyện mô hình <em>GMM</em> bao gồm những bước nào? Mỗi bước thực hiện mục tiêu gì?</p>
<p>5.- Có những siêu tham số chính nào được sử dụng để tuning mô hình <em>GMM</em>?</p>
<p>6.- Để tìm ra những siêu tham số cho mô hình <em>GMM</em> chúng ta dựa trên chỉ số nào? Chỉ số đó có ý nghĩa gì?</p>
<p>7.- Có những dạng covariance nào trong thuật toán <em>GMM</em> những dạng này có ý nghĩa gì?</p>
<p>8.- Sử dụng bộ dữ liệu <a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly">Weekly Sale Transaction</a> hãy phân chia tập train/test theo tỷ lệ 80:20.</p>
<p>9.- Tìm kiếm tham số phù hợp cho mô hình <em>GMM</em>.</p>
<p>10.- Biểu đồ hoá kết quả dự báo trên tập train và tập test.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="tai-lieu-tham-khao">
<h1>16.7. Tài liệu tham khảo<a class="headerlink" href="#tai-lieu-tham-khao" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95">https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95</a></p>
<p>[1] Bishop, Christopher M. Pattern Recognition and Machine Learning (2006) Springer-Verlag Berlin, Heidelberg.</p>
<p>[2] Murphy, Kevin P. Machine Learning: A Probabilistic Perspective (2012) MIT Press, Cambridge, Mass,</p>
<p><a class="reference external" href="https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf">https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf</a></p>
<p><a class="reference external" href="http://ttic.uchicago.edu/~shubhendu/Slides/Estimation.pdf">http://ttic.uchicago.edu/~shubhendu/Slides/Estimation.pdf</a></p>
<p><a class="reference external" href="https://web.iitd.ac.in/~sumeet/GMM_said_crv10_tutorial.pdf">https://web.iitd.ac.in/~sumeet/GMM_said_crv10_tutorial.pdf</a></p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="index_GMM.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">16. Gaussian Mixture Model</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="index_PCA.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">17. Giảm chiều dữ liệu</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Pham Dinh Khanh<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>