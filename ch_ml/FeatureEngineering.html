
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>11.1. Feature Engineering &#8212; Deep AI KhanhBlog</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"TeX": {"Macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/FeatureEngineering.html" />
    <link rel="shortcut icon" href="../_static/logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="12. Phương pháp tăng cường (Boosting)" href="index_Boosting.html" />
    <link rel="prev" title="11. Giới thiệu về feature engineering" href="index_FeatureEngineering.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/ML_course_logos.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep AI KhanhBlog</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Lời nói đầu
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../contents.html">
   Các chương dự kiến
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/main_contents.html">
   Mục tiêu cuốn sách
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../latex.html">
   Latex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../grossary.html">
   Bảng thuật ngữ
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Phụ lục
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/appendix_dtypes.html">
   1. Định dạng dữ liệu
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html">
     1.1. Các định dạng số, boolean và ký tự
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_pandas.html">
   2. Pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html">
     2.1. Khởi tạo dataframe
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_numpy.html">
   3. Numpy
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html">
     3.1. Khởi tạo một mảng trên numpy
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_matplotlib.html">
   4. Matplotlib
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html">
     4.1. Format chung của một biểu đồ trên matplotlib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_OOP.html">
   5. Lập trình hướng đối tượng (Object Oriented Programming - OOP)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html">
     5.1. Class và Object
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_pipeline.html">
   6. Sklearn Pipeline
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html">
     6.1. Thiết kế pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_Convex_Opt.html">
   7. Giới thiệu chung về optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html">
     7.1. Bài toán dạng tổng quát
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Đại số tuyến tính
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html">
   1. Đại số tuyến tính
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html">
   1. Giải tích tích phân
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Xác suất
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html">
   1. Xác suất
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index_MLIntroduce.html">
   1. Khái quát Machine Learning
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_prediction.html">
   2. Bài toán dự báo
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html">
     2.1. Ứng dụng của hồi qui tuyến tính
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_RidgedRegression.html">
   2.2. Hồi qui Ridge và Lasso
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html">
     2.2.2. Hồi qui Ridge
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_classification.html">
   3. Bài toán phân loại
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html">
     3.1. Hồi qui Logistic
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_OvfAndUdf.html">
   4. Độ chệch (
   <em>
    bias
   </em>
   ) và phương sai (
   <em>
    variance
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html">
     4.1. Sự đánh đổi giữa độ chệch và phương sai
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_ModelMetric.html">
   5. Thước đo mô hình phân loại
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html">
     5.1. Bộ dữ liệu
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_creditScorecard.html">
   6. Ứng dụng mô hình scorecard
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="creditScorecard.html">
     6.1. Phương pháp chuyên gia và mô hình
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_SVM.html">
   7. Giới thiệu về SVM
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html">
     7.1. Hàm mất mát của SVM
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_DecisionTree.html">
   8. Khái niệm về cây quyết định
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="DecisionTree.html">
     8.1. Mô hình cây quyết định (
     <em>
      decision tree
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_RandomForest.html">
   9. Giới thiệu về mô hình rừng cây (
   <em>
    Random Forest
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html">
     9.1. Ý tưởng của mô hình rừng cây
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_Bayes.html">
   10. Bạn là
   <em>
    Tần suất
   </em>
   (
   <em>
    Frequentist
   </em>
   ) hay
   <em>
    Bayesian
   </em>
   ?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html">
     10.1. Ước lượng hợp lý tối đa (
     <em>
      Maximum Likelihood Function - MLE
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index_FeatureEngineering.html">
   11. Giới thiệu về feature engineering
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     11.1. Feature Engineering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_Boosting.html">
   12. Phương pháp tăng cường (
   <em>
    Boosting
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Boosting.html">
     12.1. AdaBoosting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_KMeans.html">
   13. k-Means Clustering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html">
     13.1. Các bước của thuật toán k-Means Clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_HierarchicalClustering.html">
   14. Hierarchical Clustering (
   <em>
    phân cụm phân cấp
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html">
     14.1. Chiến lược hợp nhất (
     <em>
      agglomerative
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_DBSCAN.html">
   15. DBSCAN
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html">
     15.1. Phương pháp phân cụm dựa trên mật độ (
     <em>
      Density-Based Clustering
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_GMM.html">
   16. Gaussian Mixture Model
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="GMM.html">
     16.1. Ước lượng MLE cho
     <em>
      phân phối Gaussian đa chiều
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_PCA.html">
   17. Giảm chiều dữ liệu
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
  <label for="toctree-checkbox-24">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="PCA.html">
     17.1. Phương pháp phân tích suy biến
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Đóng góp từ những tác giả khác
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/fubini_and_riemann.html">
   Tích phân Riemann và định lý Fubini
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/information_theory.html">
   Lý thuyết thông tin
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/ch_ml/FeatureEngineering.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ch_ml/FeatureEngineering.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/phamdinhkhanh/deepai-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/phamdinhkhanh/deepai-book/issues/new?title=Issue%20on%20page%20%2Fch_ml/FeatureEngineering.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/phamdinhkhanh/deepai-book/edit/main/book/ch_ml/FeatureEngineering.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/phamdinhkhanh/deepai-book/main?urlpath=tree/book/ch_ml/FeatureEngineering.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   11.1. Feature Engineering
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#trich-loc-dac-trung-feature-extraction">
     11.1.1. Trích lọc đặc trưng (
     <em>
      Feature Extraction
     </em>
     )
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bien-doi-dac-trung-feature-transformation">
     11.1.2. Biến đổi đặc trưng (
     <em>
      Feature Transformation
     </em>
     )
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lua-chon-dac-trung-feature-selection">
     11.1.3. Lựa chọn đặc trưng (
     <em>
      Feature Selection
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   11.2. Trích lọc đặc trưng (feature extraction)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#trich-loc-dac-trung-cho-van-ban">
     11.2.1. Trích lọc đặc trưng cho văn bản
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#phuong-phap-bag-of-words">
       11.2.1.1. Phương pháp
       <em>
        bag-of-words
       </em>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#phuong-phap-bag-of-n-gram">
       11.2.1.2. Phương pháp
       <em>
        bag-of-n-gram
       </em>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#phuong-phap-tf-idf">
       11.2.1.3. Phương pháp
       <em>
        TF-IDF
       </em>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#word2vec">
       11.2.1.4. Word2vec
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#phuong-phap-cbow">
         11.2.1.4.1. Phương pháp CBOW
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#phuong-phap-skip-gram">
         11.2.1.4.2. Phương pháp skip-gram
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#su-dung-gensim-huan-luyen-mo-hinh-word2vec">
         11.2.1.4.3. Sử dụng gensim huấn luyện mô hình word2vec
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#trich-loc-dac-trung-trong-xu-ly-anh">
     11.2.2. Trích lọc đặc trưng trong xử lý ảnh
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#thong-tin-dia-ly">
     11.2.3. Thông tin địa lý
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#du-lieu-thoi-gian">
     11.2.4. Dữ liệu thời gian
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#du-lieu-tu-website-log">
     11.2.5. Dữ liệu từ website, log
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   11.3. Biến đổi đặc trưng (feature transformation)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chuan-hoa-standardization">
     11.3.1. Chuẩn hoá (
     <em>
      standardization
     </em>
     )
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ki-thuat-scaling">
     11.3.2. Kĩ thuật scaling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#minmax-scaling">
       11.3.2.1. Minmax Scaling
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#unit-length">
       11.3.2.2. Unit Length
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#robust-scaling">
       11.3.2.3. Robust Scaling
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   11.4. Lựa chọn đặc trưng (
   <em>
    feature selection
   </em>
   )
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#phuong-phap-thong-ke">
     11.4.1. Phương pháp thống kê
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#su-dung-mo-hinh">
     11.4.2. Sử dụng mô hình
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#su-dung-search">
     11.4.3. Sử dụng Search
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tong-ket">
   11.5. Tổng kết
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tai-lieu-tham-khao">
   11.6. Tài liệu tham khảo
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bai-tap">
   11.7. Bài tập
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="feature-engineering">
<h1>11.1. Feature Engineering<a class="headerlink" href="#feature-engineering" title="Permalink to this headline">¶</a></h1>
<div class="section" id="trich-loc-dac-trung-feature-extraction">
<h2>11.1.1. Trích lọc đặc trưng (<em>Feature Extraction</em>)<a class="headerlink" href="#trich-loc-dac-trung-feature-extraction" title="Permalink to this headline">¶</a></h2>
<p>Ở những bộ dữ liệu cao chiều thì huấn luyện mô hình và dự báo cần tiêu tốn rất nhiều chi phí tính toán. Chính vì thế <em>trích lọc đặc trưng</em> là một kĩ thuật giúp giảm chiều giữ liệu mà ở đó cho phép chúng ta lựa chọn hoặc kết hợp các biến đầu vào thành những <em>đặc trưng</em> dự báo nhưng vẫn thể hiện một cách chính xác và nguyên vẹn của dữ liệu gốc. <em>Trích lọc đặc trưng</em> được áp dụng trong nhiều bài toán khác nhau của machine learning.</p>
<ul class="simple">
<li><p>Autoendcoder: Là kĩ thuật khá hiệu quả trong <em>self - supervised learning</em>. Kĩ thuật này sẽ tự mã hoá dữ liệu đầu từ không gian cao chiều sang một không gian thấp chiều (quá trình <em>encoder</em>). Sau đó giải mã ngược lại từ không gian thấp chiều sang không gian cao chiều (quá trình <em>decoder</em>) sao cho thông tin đầu ra của quá trình giải mã và đầu vào phải gần bằng nhau.
<img alt="" src="https://dothanhblog.files.wordpress.com/2020/01/autoencoder.png?w=467&amp;h=354" /></p></li>
<li><p>Bag-of-Words: Hay còn gọi là <em>thuật toán túi từ</em> thường được sử dụng trong <em>xử lý ngôn ngữ tự nhiên (Natural Language Processing - NLP)</em> và <em>trích lọc thông tin (information retrieval)</em>. Thuật toán cho phép chúng ta trích lọc thông tin từ các đoạn văn bản, mẩu tin, trang web bằng cách xây dựng một <em>túi từ</em> và tìm cách mã hoá nội dung văn bản thành một véc tơ tần suất của từ mà không quan tâm đến thứ tự của từ và cấu trúc ngữ pháp.</p></li>
<li><p>Image Processing: Đây là những thuật toán được sử dụng để phát hiện đặc trưng trên ảnh như hình dạng (<em>shaped</em>) và cạnh (<em>edges</em>). Đó có thể là những phương pháp trích lọc đặc trưng trên ảnh thủ công như <a class="reference external" href="https://phamdinhkhanh.github.io/2019/11/22/HOG.html">HOG</a> và <a class="reference external" href="http://luthuli.cs.uiuc.edu/~daf/courses/ComputerVisionTutorial2012/EdgesOrientationHOGSIFT-2012.pdf">SHIFT</a> hoặc sử dụng bộ trích lọc đặc trưng thông qua tích chập <a class="reference external" href="https://phamdinhkhanh.github.io/2019/08/22/convolutional-neural-network.html">CNN</a>.</p></li>
</ul>
</div>
<div class="section" id="bien-doi-dac-trung-feature-transformation">
<h2>11.1.2. Biến đổi đặc trưng (<em>Feature Transformation</em>)<a class="headerlink" href="#bien-doi-dac-trung-feature-transformation" title="Permalink to this headline">¶</a></h2>
<p><em>Biến đổi đặc trưng</em> là những kĩ thuật giúp biến đổi dữ liệu đầu vào thành những dữ liệu phù hợp với mô hình nghiên cứu. Những dữ liệu này thường có tương quan cao đối với biến mục tiêu và do đó giúp cải thiện độ chính xác của mô hình. Bên dưới là một số phương pháp chính được áp dụng trong biến đối đặc trưng:</p>
<ul class="simple">
<li><p><strong>Chuẩn hóa biến</strong>: Chuẩn hoá biến nhằm mục đích tạo ra sự đồng nhất đơn vị giữa các biến đầu vào và giảm thiểu những tác động xấu lên mô hình do sự khác biệt về độ lớn giữa các biến. Các kĩ thuật liên quan đến chuẩn hoá đơn vị cho biến đầu vào còn được gọi là <em>Feature Scaling</em> bao gồm: <em>Chuẩn hoá MinMax (Minmax scaling</em>), <em>chuẩn hoá độ dài đơn vị</em> (<em>Unit length scaling</em>), <em>chuẩn hoá phân phối chuẩn</em> (<em>Standardization</em>).</p></li>
<li><p><strong>Biến đổi biến theo hàm</strong>: Trong trường hợp dữ liệu có <em>phương sai thay đổi (heteroscedasticity)</em> thì chúng ta có thể sử dụng một số hàm biến đổi biến đầu vào để tạo ra những biến có phương sai ổn định và dạng phân phối gần với phân phối chuẩn hơn như <code class="docutils literal notranslate"><span class="pre">logrith,</span> <span class="pre">căn</span> <span class="pre">bậc</span> <span class="pre">2,</span> <span class="pre">căn</span> <span class="pre">bậc</span> <span class="pre">3</span></code>.</p></li>
<li><p><strong>Tạo biến tương tác</strong>: Các biến tương tác là những biến kết hợp từ nhiều biến đầu vào chẳng hạn như <span class="math notranslate nohighlight">\(x_1x_2, x_1^2x_2, x_1x_2x_3^2, \dots\)</span> Biến tương tác có thể là tích của hai hoặc nhiều biến. Trong một mô hình có ít biến đầu vào thì sử dụng biến tương tác có thể giúp tạo ra nhiều biến giải thích mới giúp ích cho mô hình.</p></li>
<li><p><strong>Tạo biến bậc cao</strong>: Biến bậc cao là những biến được tạo thành từ biến đầu vào bằng cách luỹ thừa với giá trị bậc cao, có thể là bậc 2, 3,… Chẳng hạn với biến đầu vào là <span class="math notranslate nohighlight">\(x_1\)</span> thì biến bậc cao của nó là <span class="math notranslate nohighlight">\(x_1^2, x_1^3,....\)</span>.</p></li>
<li><p><strong>Dữ liệu về vị trí địa lý</strong>: Từ vị trí địa lý có thể suy ra vùng miền, thành thị, nông thôn, mức thu nhập trung bình, các yếu tố về nhân khẩu,…</p></li>
<li><p><strong>Dữ liệu thời gian</strong>: Các dữ liệu chuỗi thời gian thường tồn tại tính chu kì và mùa vụ. Chính vì vậy, các kĩ thuật biến đổi biến thời gian thành đặc trưng ghi nhận tính chất chu kì và mùa vụ sẽ giúp tăng cường khả năng giải thích của mô hình đối với biến mục tiêu. Chúng ta có thể lựa chọn chu kì của thời gian là buổi sáng/chiều/tối trong ngày; ngày trong tháng; tuần trong tháng; tháng trong năm hoặc quí trong năm tuỳ theo qui luật mùa vụ được thể hiện ở <em>biến mục tiêu</em>.</p></li>
</ul>
</div>
<div class="section" id="lua-chon-dac-trung-feature-selection">
<h2>11.1.3. Lựa chọn đặc trưng (<em>Feature Selection</em>)<a class="headerlink" href="#lua-chon-dac-trung-feature-selection" title="Permalink to this headline">¶</a></h2>
<p><em>Lựa chọn đặc trưng</em> là một phần rất quan trọng trong Machine Learning với mục tiêu chính là loại bỏ những đặc trưng không thực sự chứa thông tin hữu ích cho bài toán phân loại hoặc dự báo. Kĩ thuật <em>lựa chọn đặc trưng</em> có thể được sử dụng để cải thiện tốc độ huấn luyện và dự báo (khi có ít đặc trưng hơn có nghĩa là mô hình được huấn luyện và dự báo nhanh hơn) và thậm chí giảm hiện tượng <em>quá khớp</em>.</p>
<p>Các kĩ thuật lựa chọn đặc trưng khá đa dạng:</p>
<ul class="simple">
<li><p>Sử dụng hệ số tương quan với biến mục tiêu: Những biến tương quan cao với biến mục tiêu là những biến có khả năng giải thích tốt. Mức độ quan trọng của biến có thể được xếp hạng thông qua sử dụng tương quan Pearson Correlation,</p></li>
<li><p>Sử dụng chỉ số AIC: AIC (<em>Akaike information criterion</em>) là chỉ số được sử dụng để đánh giá chất lượng của mô hình thống kê. Chỉ số này được tính toán thông qua giá trị logarith của hàm hợp lý (<em>Log Likelihood Function</em>). Để xếp hạng mức độ quan trọng của biến thì đầu tiên chúng ta sẽ tính AIC cho mô hình được hồi qui trên toàn bộ các biến. Sau đó thực hiện các thử nghiệm huấn luyện mà mỗi lượt bỏ bớt đi một biến để xem giá trị AIC của mô hình nào là nhỏ nhất. AIC càng nhỏ thì mô hình có sai số càng thấp trên tập huấn luyện và từ đó đưa ra xếp hạng biến.</p></li>
<li><p>Sử dụng chỉ số IV: IV (<em>Information Value</em>) là chỉ số được sử dụng trong các bài toán phân loại nhị phân trong thống kê. Chỉ số này thường được đo lường để đánh giá sức mạnh phân loại của biến đầu vào.</p></li>
<li><p>Lựa chọn đặc trưng bằng sử dụng mô hình: Random Forest, Lasso Regression, Neural Network, SVD.</p></li>
<li><p>Lựa chọn thông qua mức độ biến động phương sai: Những biến ít biến động hoặc thậm chí không thay đổi giá trị sẽ không có tác dụng phân loại và dự báo. Chính vì vậy chúng ta có thể lọc bỏ những biến này thông qua xác định độ lớn của phương sai phải lớn hơn một ngưỡng cho trước.</p></li>
</ul>
<p>Tiếp theo chúng ta sẽ lần lượt phân tích những kĩ thuật này về lý thuyết, trường hợp áp dụng thông qua các ví dụ thực hành.</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1>11.2. Trích lọc đặc trưng (feature extraction)<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>Trong thực tế dữ liệu thường ở dạng thô và đến từ nhiều nguồn khác nhau như văn bản, hình ảnh, âm thanh, các phiếu điều tra, các hệ thống lưu trữ, website, app,… Nên đòi hỏi người xây dựng mô hình phải thu thập và tổng hợp lại các nguồn dữ liệu có liên quan đến vấn đề đang nghiên cứu. Dữ liệu sau đó phải được làm sạch và biến đổi thành dạng dữ liệu cấu trúc (<em>structure data</em>) để tiến hành xây dựng mô hình.</p>
<p>Đối với các dữ liệu dạng văn bản, hình ảnh hoặc âm thanh chúng ta sẽ cần đến các kĩ thuật trích lọc đặc trưng để biến dữ liệu từ dạng chưa mã hoá sang dạng số học thì mới có thể huấn luyện được mô hình. Một trong những kiểu dữ liệu phổ biến áp dụng kĩ thuật trích lọc này là dữ liệu dạng văn bản sẽ được trình bày bên dưới.</p>
<div class="section" id="trich-loc-dac-trung-cho-van-ban">
<h2>11.2.1. Trích lọc đặc trưng cho văn bản<a class="headerlink" href="#trich-loc-dac-trung-cho-van-ban" title="Permalink to this headline">¶</a></h2>
<p>Dữ liệu văn bản có thể tồn tại ở nhiều dạng khác nhau như chữ cái thường, chữ cái hoa, dấu câu, các kí tự đặc biệt,… Các ngôn ngữ khác nhau cũng có mẫu kí tự khác nhau và cấu trúc ngữ pháp khác nhau.</p>
<p>Vấn đề chính của dữ liệu dạng văn bản đó là làm thể nào để mã hoá được kí tự về dạng số? Kĩ thuật <em>tokenization</em> sẽ giúp ta thực hiện điều này. <em>tokenization</em> là việc chúng ta chia văn bản theo đơn vị nhỏ nhất và xây dựng một từ điển đánh dấu index cho những đơn vị này. Có hai kiểu mã hoá chính là mã hoá theo từ và mã hoá theo kí tự.</p>
<ul class="simple">
<li><p>Đối với mã hoá theo từ thì các từ trong câu sẽ là đơn vị nhỏ nhất. Trong Tiếng Anh thì từ chủ yếu tồn tại ở dạng từ đơn trong khi Tiếng Việt tồn tại các từ ghép. Khi mã hoá theo từ thì kích thước của từ điển sẽ rất lớn, tuỳ thuộc vào số lượng các từ khác nhau xuất hiện trong toàn bộ các văn bản.</p></li>
<li><p>Mã hoá theo kí tự thì chúng ta sẽ sử dụng các kí hiệu trong bảng chữ cái để làm từ điển mã hoá từ. Kích thước của bộ từ điển khi mã hoá theo kí tự sẽ nhỏ hơn so với mã hoá theo từ.</p></li>
</ul>
<div class="section" id="phuong-phap-bag-of-words">
<h3>11.2.1.1. Phương pháp <em>bag-of-words</em><a class="headerlink" href="#phuong-phap-bag-of-words" title="Permalink to this headline">¶</a></h3>
<p><em>bag-of-words</em>, viết tắt là BoW, có nghĩa là bỏ túi các từ. Theo phương pháp <em>bag-of-word</em> chúng ta sẽ mã hoá các từ trong câu thành một véc tơ có độ dài bằng số lượng các từ trong từ điển và đếm tần suất xuất hiện của các từ. Tần xuất của từ thứ <span class="math notranslate nohighlight">\(i\)</span> trong từ điển sẽ chính bằng phần tử thứ <span class="math notranslate nohighlight">\(i\)</span> trong véc tơ.</p>
<p><img alt="" src="https://imgur.com/UuynVys.jpeg" /></p>
<p><strong>Hình 1:</strong> Văn bản ở bên trái được mã hoá thành véc tơ tần suất từ ở bên phải. Các từ <code class="docutils literal notranslate"><span class="pre">I</span></code> và <code class="docutils literal notranslate"><span class="pre">have</span></code> lặp lại 2 lần nên có tần suất là 2. Những từ không xuất hiện trong câu nhưng có trong từ điển như <code class="docutils literal notranslate"><span class="pre">deep,</span> <span class="pre">is,</span> <span class="pre">this,</span> <span class="pre">machine,</span> <span class="pre">learning</span></code> thì có giá trị là 0.</p>
<p>Như vậy theo phương pháp <em>bag-of-words</em> thì mỗi từ sẽ trở thành một chiều biểu diễn trong không gian của véc tơ đầu ra. Khi số lượng các từ rất lớn thì kết quả mã hoá có thể tạo thành một véc tơ có độ dài rất lớn. Thông thường đây sẽ là một véc tơ thưa (<em>sparse vector</em>) có hầu hết các giá trị bằng 0. Số lượng chiều lớn khiến việc biểu diễn các véc tơ mã hoá trên không gian gặp khó khăn. Nếu như ta muốn biểu diễn trên đồ thị thì phải tìm cách giảm chiều véc tơ xuống còn 2 hoặc 3 chiều.</p>
<p>Bên dưới là code minh hoạ cho phương pháp túi từ. Để xây dựng phương pháp túi từ chúng ta trải qua hai bước:</p>
<ol class="simple">
<li><p>Xây dựng từ điển.</p></li>
<li><p>Mã hoá văn bản sang véc tơ tần suất của từ.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">reduce</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Đầu vào là một texts bao gồm 3 câu văn:</span>
<span class="n">texts</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="s1">&#39;have&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">],</span> 
        <span class="p">[</span><span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;has&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">],</span> 
        <span class="p">[</span><span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;has&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;and&#39;</span><span class="p">,</span> <span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="s1">&#39;have&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">]]</span>

<span class="c1"># B1: Xây dựng từ điển</span>
<span class="n">dictionary</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">,</span> <span class="n">texts</span><span class="p">))))</span>

<span class="c1"># B2: Mã hoá câu sang véc tơ tần suất</span>
<span class="k">def</span> <span class="nf">bag_of_word</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="c1"># Khởi tạo một vector có độ dài bằng với từ điển.</span>
    <span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dictionary</span><span class="p">))</span>
    <span class="c1"># Đếm các từ trong một câu xuất hiện trong từ điển.</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">:</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># Đếm số từ xuất hiện trong một câu.</span>
        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">w</span> <span class="o">==</span> <span class="n">word</span><span class="p">:</span>
                <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">vector</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span>
    <span class="k">return</span> <span class="n">vector</span>
            
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">bag_of_word</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1. 1. 1. 1. 0. 0. 0. 0.]
[0. 0. 0. 1. 1. 1. 1. 0.]
[1. 1. 1. 2. 1. 1. 1. 1.]
</pre></div>
</div>
</div>
</div>
<p>Nếu muốn sử dụng thư viện để tìm biểu diễn <em>bag-of-words</em> của từ thì trong sklearn chúng ta sử dụng package như sau:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;i have a cat&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;he has a dog&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;he has a dog and i have a cat&#39;</span><span class="p">]</span>

<span class="n">vect</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">vect</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;words in dictionary: &#39;</span><span class="p">,</span> <span class="n">vect</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>words in dictionary:  [&#39;and&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;has&#39;, &#39;have&#39;, &#39;he&#39;]
[[0 1 0 0 1 0]
 [0 0 1 1 0 1]
 [1 1 1 1 1 1]]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/khanh/miniconda3/envs/deepai-book/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)
</pre></div>
</div>
</div>
</div>
<p>Quá trình này có thể được mô tả bởi biểu đồ bên dưới:</p>
<p><img alt="" src="https://imgur.com/JgITfRU.jpeg" /></p>
<p>Các biểu diễn theo túi từ có hạn chế đó là chúng ta không phân biệt được 2 câu văn có cùng các từ bởi túi từ không phân biệt thứ tự trước sau của các từ trong một câu. Chặng như ‘you have no dog’ và ‘no, you have dog’ là 2 câu văn có biểu diễn giống nhau mặc dù có ý nghĩa trái ngược nhau.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vect</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">vect</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="s1">&#39;you have no dog&#39;</span><span class="p">,</span> <span class="s1">&#39;no, you have dog&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1, 1, 1, 1],
       [1, 1, 1, 1]])
</pre></div>
</div>
</div>
</div>
<p>Chính vì thế phương pháp <em>bag-of-n-gram</em> sẽ được sử dụng thay thế.</p>
</div>
<div class="section" id="phuong-phap-bag-of-n-gram">
<h3>11.2.1.2. Phương pháp <em>bag-of-n-gram</em><a class="headerlink" href="#phuong-phap-bag-of-n-gram" title="Permalink to this headline">¶</a></h3>
<p>Phương pháp <em>bag-of-n-grams</em> là phương pháp mở rộng của <em>bag-of-words</em>. Một <em>n-grams</em> là một chuỗi bao gồm <span class="math notranslate nohighlight">\(n\)</span> tokens. Trong trường hợp <span class="math notranslate nohighlight">\(n=1\)</span> từ ta gọi là <em>unigram</em>, đối với 2 từ là <em>bigram</em> và 3 từ là <em>trigram</em>. Khi thực hiện tokenization với <em>n-grams</em> thì trong từ điển sẽ xuất hiện những cụm <span class="math notranslate nohighlight">\(n-grams\)</span> từ nếu chúng xuất hiện trong các văn bản. Chẳng hạn như câu <code class="docutils literal notranslate"><span class="pre">I</span> <span class="pre">have</span> <span class="pre">a</span> <span class="pre">dog</span></code> sẽ được tokenize thành <code class="docutils literal notranslate"><span class="pre">I</span> <span class="pre">have,</span> <span class="pre">have</span> <span class="pre">a,</span> <span class="pre">a</span> <span class="pre">dog</span></code>. Như vậy số lượng các từ trong từ điển sẽ gia tăng một cách đáng kể. Nếu chúng ta có <span class="math notranslate nohighlight">\(k\)</span> từ đơn thì có thể lên tới <span class="math notranslate nohighlight">\(k^2\)</span> từ trong bigram. Nhưng thực tế không phải hầu hết các từ đều có thể ghép đôi với nhau nên véc tơ biểu diễn của câu trong <em>bigram</em> là một véc tơ rất thưa và có số chiều lớn. Điều này dẫn tới tốn kém về chi phí tính toán và lưu trữ.</p>
<p>Trong <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>, để sử dụng <em>bigram</em> thì trong <code class="docutils literal notranslate"><span class="pre">CountVectorizer</span></code> chúng ta thay đổi <code class="docutils literal notranslate"><span class="pre">ngram_range</span> <span class="pre">=</span> <span class="pre">(2,</span> <span class="pre">2)</span></code>. Giá trị đầu tiên là độ dài nhỏ nhất và giá trị sau là độ dài lớn nhất được phép của các <em>ngrams</em>. Ở đây ta khai báo độ dài nhỏ nhất và lớn nhất là 2 nên thu được <em>ngrams</em> là <em>bigram</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="c1"># bigram</span>
<span class="n">bigram</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n3</span> <span class="o">=</span> <span class="n">bigram</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="s1">&#39;you have no dog&#39;</span><span class="p">,</span> <span class="s1">&#39;no, you have dog&#39;</span><span class="p">,</span> <span class="s1">&#39;you have a dog&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

<span class="c1"># trigram</span>
<span class="n">trigram</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n3</span> <span class="o">=</span> <span class="n">trigram</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="s1">&#39;you have no dog&#39;</span><span class="p">,</span> <span class="s1">&#39;no, you have dog&#39;</span><span class="p">,</span> <span class="s1">&#39;you have a dog&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Sau khi mã hoá các câu văn chúng ta cũng có thể tính toán được khoảng cách giữa các véc tơ trong không gian euclidean:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">euclidean</span>
<span class="nb">print</span><span class="p">(</span><span class="n">euclidean</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">),</span> <span class="n">euclidean</span><span class="p">(</span><span class="n">n2</span><span class="p">,</span> <span class="n">n3</span><span class="p">),</span> <span class="n">euclidean</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.0 1.0 1.7320508075688772
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="phuong-phap-tf-idf">
<h3>11.2.1.3. Phương pháp <em>TF-IDF</em><a class="headerlink" href="#phuong-phap-tf-idf" title="Permalink to this headline">¶</a></h3>
<p>Giả sử chúng ta có một <em>bộ văn bản</em> (<em>corpus</em>) bao gồm rất nhiều các văn bản con. Những từ hiếm khi được tìm thấy trong bộ văn bản (<em>corpus</em>) nhưng có mặt trong một số chủ đề nhất định có thể chiếm vai trò quan trọng hơn. Ví dụ đối với chủ đề gia đình thì các từ như <code class="docutils literal notranslate"><span class="pre">cha</span> <span class="pre">mẹ,</span> <span class="pre">ông</span> <span class="pre">bà,</span> <span class="pre">con</span> <span class="pre">cái,</span> <span class="pre">anh</span> <span class="pre">em,</span> <span class="pre">chị</span> <span class="pre">em</span></code> xuất hiện nhiều hơn so với các chủ đề khác.</p>
<p>Ngoài ra cũng có những từ xuất hiện rất nhiều trong văn bản nhưng chúng xuất hiện ở hầu như mọi chủ đề, mọi văn bản chẳng hạn như <code class="docutils literal notranslate"><span class="pre">the,</span> <span class="pre">a,</span> <span class="pre">an</span></code>. Những từ như vậy được gọi là  <em>stopwords</em> vì chúng không có nhiều ý nghĩa đối với việc phân loại văn bản. Khi mã hoá ngôn ngữ thì chúng ta sẽ tìm cách loại bỏ những từ <em>stopwords</em> bằng cách sử dụng từ điển có sẵn các từ <em>stopwords</em> quan trọng.</p>
<p>Phương pháp TF-IDF là một phương pháp mà chúng ta sẽ đánh trọng số cho các từ mà xuất hiện ở một vài văn bản cụ thể lớn hơn thông qua công thức:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\text{idf}(t,D) &amp; = &amp; \log\frac{\mid D \mid}{|\{d \in D; t \in d \}|+ 1} = \log \frac{\mid D\mid}{\text{df}(d, t)+ 1} \\
\text{tfidf}(t,d,D) &amp; = &amp; \text{tf}(t,d) \times \text{idf}(t,D)
\end{eqnarray}\end{split}\]</div>
<p>trong đó:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mid D \mid\)</span> là số lượng các văn bản trong <em>bộ văn bản</em>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{df}(d, t) = |\{d \in D; t \in d \}|\)</span> là tần suất các văn bản <span class="math notranslate nohighlight">\(d \in D\)</span> mà từ <span class="math notranslate nohighlight">\(t\)</span> xuất hiện.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{tf}(t,d)\)</span> là tần suất xuất hiện của từ <span class="math notranslate nohighlight">\(t\)</span> trong văn bản <span class="math notranslate nohighlight">\(d\)</span>.</p></li>
</ul>
<p>Như vậy <span class="math notranslate nohighlight">\(\text{idf}(t, D)\)</span> là chỉ số <em>nghịch đảo tần suất văn bản</em> (<em>inverse document frequency</em>) chỉ số này bằng logarith của nghịch đảo số lượng văn bản chia cho số lượng văn bản chứa một từ cụ thể <span class="math notranslate nohighlight">\(t\)</span>. Một từ cụ thể có <span class="math notranslate nohighlight">\(\text{idf}(t,D)\)</span> lớn chứng tỏ rằng từ đó chỉ xuất hiện trong một số ít các văn bản.</p>
<p><span class="math notranslate nohighlight">\(\text{tfidf}(t, d, D)\)</span> tỷ lệ thuận với <em>tần suất của từ xuất hiện trong văn bản</em> và <em>nghịch đảo tần suất văn bản</em>. Ta có thể giải thích ý nghĩa của <span class="math notranslate nohighlight">\(\text{tfidf}\)</span> đối với đánh giá mức độ quan trọng của từ như sau: Khi một từ càng quan trọng thì nó sẽ có tần suất xuất hiện trong một văn bản cụ thể, chẳng hạn văn bản <span class="math notranslate nohighlight">\(d\)</span> lớn, tức là <span class="math notranslate nohighlight">\(\text{tf}(t,d)\)</span> lớn; Đồng thời từ đó phải không là <em>stopwords</em>, tức là số lượng văn bản mà nó xuất hiện trong toàn bộ bộ văn bản nhỏ, suy ra <span class="math notranslate nohighlight">\(\text{idf}(t, D)\)</span> phải lớn.</p>
<p>Để mã hoá văn bản dựa trên phương pháp tfidf chúng ta sử dụng package <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> như sau:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
 	<span class="s1">&#39;tôi thích ăn bánh mì nhân thịt&#39;</span><span class="p">,</span>
	<span class="s1">&#39;cô ấy thích ăn bánh mì, còn tôi thích ăn xôi&#39;</span><span class="p">,</span>
	<span class="s1">&#39;thị trường chứng khoán giảm làm tôi lo lắng&#39;</span><span class="p">,</span>
	<span class="s1">&#39;chứng khoán sẽ phục hồi vào thời gian tới. danh mục của tôi sẽ tăng trở lại&#39;</span><span class="p">,</span>
  <span class="s1">&#39;dự báo thời tiết hà nội có mưa vào chiều và tối. tôi sẽ mang ô khi ra ngoài&#39;</span>
<span class="p">]</span>

<span class="c1"># Tính tfidf cho mỗi từ. max_df để loại bỏ stopwords xuất hiện ở hơn 90% các câu</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_df</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="c1"># Tokenize các câu theo tfidf</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;words in dictionary:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X shape: &#39;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>words in dictionary:
[&#39;bánh&#39;, &#39;báo&#39;, &#39;chiều&#39;, &#39;chứng&#39;, &#39;còn&#39;, &#39;có&#39;, &#39;cô&#39;, &#39;của&#39;, &#39;danh&#39;, &#39;dự&#39;, &#39;gian&#39;, &#39;giảm&#39;, &#39;hà&#39;, &#39;hồi&#39;, &#39;khi&#39;, &#39;khoán&#39;, &#39;lo&#39;, &#39;làm&#39;, &#39;lại&#39;, &#39;lắng&#39;, &#39;mang&#39;, &#39;mì&#39;, &#39;mưa&#39;, &#39;mục&#39;, &#39;ngoài&#39;, &#39;nhân&#39;, &#39;nội&#39;, &#39;phục&#39;, &#39;ra&#39;, &#39;sẽ&#39;, &#39;thích&#39;, &#39;thị&#39;, &#39;thịt&#39;, &#39;thời&#39;, &#39;tiết&#39;, &#39;trường&#39;, &#39;trở&#39;, &#39;tăng&#39;, &#39;tối&#39;, &#39;tới&#39;, &#39;và&#39;, &#39;vào&#39;, &#39;xôi&#39;, &#39;ăn&#39;, &#39;ấy&#39;]
X shape:  (5, 45)
</pre></div>
</div>
</div>
</div>
<p>Ta có thể thấy từ <code class="docutils literal notranslate"><span class="pre">tôi</span></code> xuất hiện ở toàn bộ các câu và không mang nhiều ý nghĩa của chủ đề của câu nên có thể coi là một <em>stopword</em>. Bằng phương pháp lọc cận trên của tần suất xuất hiện từ trong văn bản là 90% ta đã loại bỏ được từ này khỏi dictionary.</p>
<p>Các phương pháp bỏ túi có thể tìm được một số cuộc thi trên kaggle như <a class="reference external" href="https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking">Catch me if you can competition</a>, <a class="reference external" href="https://www.kaggle.com/xiaoml/bag-of-app-id-python-2-27392">bag of app</a>, <a class="reference external" href="http://www.interdigital.com/download/58540a46e3b9659c9f000372">bag of event</a>:</p>
</div>
<div class="section" id="word2vec">
<h3>11.2.1.4. Word2vec<a class="headerlink" href="#word2vec" title="Permalink to this headline">¶</a></h3>
<p>Word2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located close to one another in the space.[1]</p>
<p>word2vec là một nhóm các mô hình sử dụng để tạo ra biểu diễn nhúng cho từ. Những mô hình này tương đối nông, chỉ bao gồm những mạng neural 2 layers được huấn luyện để tái tạo lại bối cảnh ngôn ngữ cho từ. Thông qua mô hình word2vec mỗi một từ trong một <em>bộ văn bản</em> được biểu diễn thông qua một véc tơ trong không gian cao chiều, có thể lên tới hàng trăm chiều, sao cho các từ có chung ngữ cảnh sẽ được đặt gần nhau hơn trong không gian.</p>
<p>Chẳng hạn dưới đây là một ví dụ sau khi thực hiện mã hoá từ thông qua mô hình word2vec thì các từ <code class="docutils literal notranslate"><span class="pre">king,</span> <span class="pre">queen,</span> <span class="pre">man,</span> <span class="pre">woman</span></code> có mối liên hệ theo công thức: king - man + woman = queen</p>
<p><img alt="" src="https://camo.githubusercontent.com/7acb5beb08711a6e75b6eadb90fdf48fb67c67d87f45812dc8cbd8426c1ee44f/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a4b3558344e2d4d4a4b743846474674725448776964672e676966" /></p>
<p><strong>Hình 2</strong>: Mô hình word2vec đã định vị véc tơ biểu diễn cho những từ có chung ngữ cảnh thì được đặt gần nhau hơn. Để thực hiện được những biểu diễn từ chính xác, các mô hình cần được đào tạo trên các tập dữ liệu rất lớn để bao quát được đa dạng các ngữ cảnh khác nhau của từ. Các mô hình pretrained cho xử lý ngôn ngữ tự nhiên có thể được tải về tại <a class="reference external" href="https://github.com/3Top/word2vec-api#where-to-get-a-pretrained-models">word2vec - api</a>.</p>
<p>Các phương pháp tương tự được áp dụng trong các lĩnh vực khác như trong tin sinh. Một ứng dụng khác nữa là <a class="reference external" href="https://jaan.io/food2vec-augmented-cooking-machine-intelligence/">food2vec</a>.</p>
<p>Tại một vị trí cụ thể trong câu văn chúng ta sẽ xác định được một từ mục tiêu và các từ bối cảnh. Từ mục tiêu là từ ở vị trí được lựa chọn còn từ bối cảnh là những từ ở vị trí xung quanh giúp tạo ra bối cảnh ngữ nghĩa cho từ mục tiêu.</p>
<p>Giả sử chúng ta có một câu văn như sau: “Tôi muốn một chiếc cốc màu xanh”. Nếu lựa chọn một <em>context window</em> bao gồm 3 từ liền kề thì chúng ta sẽ lần lượt thu được các bộ 3 từ: <code class="docutils literal notranslate"><span class="pre">tôi</span> <span class="pre">muốn</span> <span class="pre">một,</span> <span class="pre">muốn</span> <span class="pre">một</span> <span class="pre">chiếc,</span> <span class="pre">một</span> <span class="pre">chiếc</span> <span class="pre">cốc,</span> <span class="pre">chiếc</span> <span class="pre">cốc</span> <span class="pre">màu,</span> <span class="pre">cốc</span> <span class="pre">màu</span> <span class="pre">xanh</span></code>. Đối với những bộ 3 từ này thì các từ ở giữa sẽ là từ mục tiêu và từ bối cảnh là những từ ở đầu và ở cuối. Như vậy chúng ta sẽ có các cặp từ mục tiêu và bối cảnh như sau:</p>
<p><code class="docutils literal notranslate"><span class="pre">[(('tôi',</span> <span class="pre">'một'),</span> <span class="pre">'muốn'),</span> <span class="pre">(('muốn',</span> <span class="pre">'chiếc'),</span> <span class="pre">'một'),</span> <span class="pre">(('một',</span> <span class="pre">'cốc'),</span> <span class="pre">'chiếc'),</span> <span class="pre">(('chiếc',</span> <span class="pre">'màu'),</span> <span class="pre">'cốc'),</span> <span class="pre">(('cốc',</span> <span class="pre">'xanh'),</span> <span class="pre">'màu')]</span></code></p>
<p>Mô hình word2vec có 2 phương pháp chính là skip-grams và CBOW như sau:</p>
<p><img alt="" src="https://imgur.com/41qQJ2u.jpeg" /></p>
<p><strong>Hình 3:</strong> Mô hình CBOW và Skip-gram trong word2vec.</p>
<div class="section" id="phuong-phap-cbow">
<h4>11.2.1.4.1. Phương pháp CBOW<a class="headerlink" href="#phuong-phap-cbow" title="Permalink to this headline">¶</a></h4>
<p>Đối với mô hình CBOW chúng ta sẽ xây dựng một mô hình học có giám sát sử dụng đầu vào là các từ bối cảnh, chẳng hạn như trong hình là các từ <span class="math notranslate nohighlight">\(\mathbf{w}_{t-2}, \mathbf{w}_{t-1}, \mathbf{w}_{t+1}, \mathbf{w}_{t+2}\)</span> để giải thích từ mục tiêu ở vị trí hiện tại là <span class="math notranslate nohighlight">\(\mathbf{w}_t\)</span>.</p>
<p>Các từ <span class="math notranslate nohighlight">\(\mathbf{w}_t\)</span> đã được mã hoá dưới dạng véc tơ one-hot trong không gian <span class="math notranslate nohighlight">\(\mathbb{R}^{d}\)</span> chiều để có thể đưa vào huấn luyện. Ở đây <span class="math notranslate nohighlight">\(d\)</span> chính là kích thước của từ điển. Như vậy ở phương pháp CBOW chúng ta có 5 véc tơ one-hot đầu vào với số chiều bằng với số lượng từ trong từ điển. Sau đó những véc tơ này được giảm chiều dữ liệu thông qua một phép chiếu lên không gian thấp chiều, chẳng hạn 200 chiều, bước này chính là projection trên hình vẽ. Kết quả thu được là một véc tơ embedding <span class="math notranslate nohighlight">\(\mathbf{e}_c \in \mathbb{R}^{200}\)</span>. Sau cùng, phân phối xác suất của từ mục tiêu được dự báo thông qua một hàm softmax áp dụng lên véc tơ <span class="math notranslate nohighlight">\(\mathbf{e}_c\)</span>. Quá trình huấn luyện mô hình sẽ dựa trên hàm softmax dạng cross-entropy:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\mathbf{y}, \hat{\mathbf{y}}) = -\sum_{i=1}^{d} y_i\log(\hat{y}_i)\]</div>
<p>Trong đó <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> là xác suất dự báo từ mục tiêu tương ứng với từ ở vị trí index thứ <span class="math notranslate nohighlight">\(i\)</span> trong từ điển, được tính theo công thức softmax:</p>
<div class="math notranslate nohighlight">
\[\hat{y_i} = \frac{\exp(\mathbf{w}_{:i}^{\intercal}\mathbf{e}_c)}{\sum_{i=1}^{d}\exp(\mathbf{w}_{:i}^{\intercal}\mathbf{e}_c)}\]</div>
<p><span class="math notranslate nohighlight">\(\mathbf{w}_{:i} \in \mathbb{R}^{200}\)</span> chính là véc tơ tham số kết nối toàn bộ các node thuộc <span class="math notranslate nohighlight">\(\mathbf{e}_c\)</span> tới vị trí node thứ <span class="math notranslate nohighlight">\(i\)</span> của layer cuối cùng.</p>
<p>Sau quá trình lan truyền thuận và lan truyền ngược, các hệ số của mô hình sẽ được cập nhật và chúng ta sẽ thu được biểu diễn từ dần chuẩn xác hơn. Một từ đầu vào sẽ có biểu diễn thông qua phương pháp CBOW chính là véc tơ <span class="math notranslate nohighlight">\(\mathbf{e}_c\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">text</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">sequence</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">gutenberg</span>
<span class="kn">from</span> <span class="nn">string</span> <span class="kn">import</span> <span class="n">punctuation</span>
<span class="kn">import</span> <span class="nn">nltk</span>

<span class="c1"># download bộ văn bản gutenberg</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;gutenberg&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
<span class="n">norm_bible</span> <span class="o">=</span> <span class="n">gutenberg</span><span class="o">.</span><span class="n">sents</span><span class="p">(</span><span class="s1">&#39;bible-kjv.txt&#39;</span><span class="p">)</span> 
<span class="n">norm_bible</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">norm_bible</span><span class="p">]</span>

<span class="c1"># tokenize văn bản</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">Tokenizer</span><span class="p">()</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">norm_bible</span><span class="p">)</span>
<span class="n">word2id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span>

<span class="c1"># khởi tạo từ điển cho bộ văn bản</span>
<span class="n">word2id</span><span class="p">[</span><span class="s1">&#39;PAD&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">id2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">word2id</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word2id</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Vocabulary Size:&#39;</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Vocabulary Sample:&#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">word2id</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_43532</span><span class="o">/</span><span class="mf">3096796808.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">sequence</span>
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">gutenberg</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">from</span> <span class="nn">string</span> <span class="kn">import</span> <span class="n">punctuation</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="kn">import</span> <span class="nn">nltk</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;nltk&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mã hoá câu văn bằng index</span>
<span class="n">wids</span> <span class="o">=</span> <span class="p">[[</span><span class="n">word2id</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">text_to_word_sequence</span><span class="p">(</span><span class="n">doc</span><span class="p">)]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">norm_bible</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Embedding sentence by index: &#39;</span><span class="p">,</span> <span class="n">wids</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">script</span> echo skipping
# Xác định context and target
import numpy as np
def generate_context_word_pairs(corpus, window_size, vocab_size):
    context_length = window_size*2
    for words in corpus:
        sentence_length = len(words)
        # print(&#39;words: &#39;, words)
        for index, word in enumerate(words):
            context_words = []
            label_word   = [] 
            # Start index of context
            start = index - window_size
            # End index of context
            end = index + window_size + 1
            # List of context_words
            context_words.append([words[i] for i in range(start, end) if 0 &lt;= i &lt; sentence_length and i != index])
            # List of label_word (also is target word).
            # print(&#39;context words {}: {}&#39;.format(context_words, index))
            label_word.append(word)
            # Padding the input 0 in the left in case it does not satisfy number of context_words = 2*window_size.
            x = sequence.pad_sequences(context_words, maxlen=context_length)
            # print(&#39;context words padded: &#39;, x)
            # Convert label_word into one-hot vector corresponding with its index
            y = to_categorical(label_word, vocab_size)
            yield (x, y)
            
            
# Test this out for some samples
i = 0
window_size = 2 # context window size
for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):
    if 0 not in x[0]:
        print(&#39;Context (X):&#39;, [id2word[w] for w in x[0]], &#39;-&gt; Target (Y):&#39;, id2word[np.argwhere(y[0])[0][0]])
    
        if i == 10:
            break
        i += 1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Xây dựng mô hình CBOW là một mạng fully connected gồm 3 layers</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Lambda</span>
<span class="n">embed_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">window_size</span><span class="o">=</span><span class="mi">2</span>
<span class="c1"># build CBOW architecture</span>
<span class="n">cbow</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">cbow</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">window_size</span><span class="o">*</span><span class="mi">2</span><span class="p">))</span>
<span class="n">cbow</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,)))</span>
<span class="n">cbow</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="n">cbow</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">)</span>

<span class="c1"># view model summary</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cbow</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">script</span> echo skipping
# Huấn luyện model với 5 epochs với 100 quan sát đầu tiên

for epoch in range(1, 6):
    loss = 0.
    i = 0
    for x, y in generate_context_word_pairs(corpus=wids[:100], window_size=window_size, vocab_size=vocab_size):
        i += 1
        loss += cbow.train_on_batch(x, y)
        if i % 500 == 0:
            print(&#39;Processed {} (context, word) pairs&#39;.format(i))

    print(&#39;Epoch:&#39;, epoch, &#39;\tLoss:&#39;, loss)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="phuong-phap-skip-gram">
<h4>11.2.1.4.2. Phương pháp skip-gram<a class="headerlink" href="#phuong-phap-skip-gram" title="Permalink to this headline">¶</a></h4>
<p>Phương pháp skip-gram thực chất là một phiên bản đảo ngược của phương pháp CBOW. Chúng ta sẽ sử dụng đầu vào là các từ mục tiêu và dự báo các từ bối cảnh dự vào từ mục tiêu. Như thể hiện ở <em>hình 3</em> thì <span class="math notranslate nohighlight">\(\mathbf{w}_t\)</span> chính là từ mục tiêu được sử dụng làm đầu vào, các từ <span class="math notranslate nohighlight">\(\mathbf{w}_{t-2}, \mathbf{w}_{t-1}, \mathbf{w}_{t+1}, \mathbf{w}_{t+2}\)</span> là những từ bối cảnh cần được dự đoán. Những từ này đều được mã hoá thành véc tơ one-hot trong không gian <span class="math notranslate nohighlight">\(\mathbb{R}^{d}\)</span>. Sau đó véc tơ one-hot sẽ được chiếu lên không gian nhằm giảm chiều dữ liệu xuống còn chẳng hạn <span class="math notranslate nohighlight">\(200\)</span> chiều. Đầu ra thu được là véc tơ <span class="math notranslate nohighlight">\(\mathbf{e}_c\)</span> có kích thước 200, đây cũng chính là biểu diễn nhúng của từ trong skip-gram. Cuối cùng chúng ta sử dụng một sigmoid layer để dự đoán xem từ mục tiêu <span class="math notranslate nohighlight">\(\mathbf{w}_t\)</span> và từ bối cảnh <span class="math notranslate nohighlight">\(\mathbf{w}_j\)</span> (<span class="math notranslate nohighlight">\(\mathbf{w}_j\)</span> được lựa chọn ngẫu nhiên từ từ điển) có cùng bối cảnh hay không?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">skipgrams</span>

<span class="n">window_size</span><span class="o">=</span><span class="mi">2</span>
<span class="c1"># generate skip-grams</span>
<span class="n">skip_grams</span> <span class="o">=</span> <span class="p">[</span><span class="n">skipgrams</span><span class="p">(</span><span class="n">wid</span><span class="p">,</span> <span class="n">vocabulary_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="n">window_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">wid</span> <span class="ow">in</span> <span class="n">wids</span><span class="p">[:</span><span class="mi">100</span><span class="p">]]</span>

<span class="c1"># view sample skip-grams</span>
<span class="n">pairs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">skip_grams</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_grams</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(</span><span class="si">{:s}</span><span class="s2"> (</span><span class="si">{:d}</span><span class="s2">), </span><span class="si">{:s}</span><span class="s2"> (</span><span class="si">{:d}</span><span class="s2">)) -&gt; </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
          <span class="n">id2word</span><span class="p">[</span><span class="n">pairs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]],</span> <span class="n">pairs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> 
          <span class="n">id2word</span><span class="p">[</span><span class="n">pairs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span> <span class="n">pairs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> 
          <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">dot</span><span class="p">,</span> <span class="n">concatenate</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Input</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dot</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Reshape</span><span class="p">,</span> <span class="n">Embedding</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>

<span class="c1"># build skip-gram architecture</span>
<span class="n">word_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
<span class="n">word_embed</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span>
                         <span class="n">embeddings_initializer</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span>
                         <span class="n">input_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;word_embedding&#39;</span><span class="p">)(</span><span class="n">word_input</span><span class="p">)</span>
<span class="n">word_output</span> <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="n">embed_size</span><span class="p">,</span> <span class="p">))(</span><span class="n">word_embed</span><span class="p">)</span>
<span class="n">word_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">word_input</span><span class="p">,</span> <span class="n">word_output</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;word_model: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">word_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="n">context_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
<span class="n">context_embed</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span>
                  <span class="n">embeddings_initializer</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span>
                  <span class="n">input_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;context_embedding&#39;</span><span class="p">)(</span><span class="n">context_input</span><span class="p">)</span>
<span class="n">context_output</span> <span class="o">=</span> <span class="n">Reshape</span><span class="p">((</span><span class="n">embed_size</span><span class="p">,))(</span><span class="n">context_embed</span><span class="p">)</span>
<span class="n">context_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">context_input</span><span class="p">,</span> <span class="n">context_output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;context_model: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">context_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

<span class="n">concate</span> <span class="o">=</span> <span class="n">dot</span><span class="p">([</span><span class="n">word_output</span><span class="p">,</span> <span class="n">context_output</span><span class="p">],</span> <span class="n">axes</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dense</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">concate</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_input</span><span class="p">,</span> <span class="n">context_input</span><span class="p">],</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">dense</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mean_squared_error&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">)</span>

<span class="c1"># view model summary</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;model merge word and context: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">script</span> echo skipping
# Để cho nhanh thì mình sẽ training trên 100 skip_grams đầu tiên.
for epoch in range(1, 6):
    loss = 0
    for i, elem in enumerate(skip_grams[:100]):
        pair_first_elem = np.array(list(zip(*elem[0]))[0], dtype=&#39;int32&#39;)
        pair_second_elem = np.array(list(zip(*elem[0]))[1], dtype=&#39;int32&#39;)
        labels = np.array(elem[1], dtype=&#39;int32&#39;)
        X = [pair_first_elem, pair_second_elem]
        Y = labels
        if i % 500 == 0:
            print(&#39;Processed {} (skip_first, skip_second, relevance) pairs&#39;.format(i))
        loss += model.train_on_batch(X,Y)  

    print(&#39;Epoch:&#39;, epoch, &#39;Loss:&#39;, loss)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="su-dung-gensim-huan-luyen-mo-hinh-word2vec">
<h4>11.2.1.4.3. Sử dụng gensim huấn luyện mô hình word2vec<a class="headerlink" href="#su-dung-gensim-huan-luyen-mo-hinh-word2vec" title="Permalink to this headline">¶</a></h4>
<p>Huấn luyện mô hình word2vec sử dụng mạng nơ ron là để chúng ta hiểu rõ hơn về cấu trúc mạng nơ ron và cách thức hoạt động của mạng. Trên thực tế để huấn luyện mô hình word2vec chúng ta có thể thông qua package gensim như sau:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>
<span class="c1"># Training model với 1000 câu đầu tiên trong kinh thánh</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[[</span><span class="n">item</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">norm_bible</span><span class="p">[:</span><span class="mi">1000</span><span class="p">]]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">min_count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">vector_size</span> <span class="o">=</span> <span class="mi">150</span><span class="p">,</span> <span class="n">window</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">sg</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">workers</span> <span class="o">=</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">total_examples</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">corpus_count</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Tìm biểu diễn véc tơ nhúng của một từ:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;embedding vector shape: &#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="s1">&#39;king&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="s1">&#39;king&#39;</span><span class="p">][:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="trich-loc-dac-trung-trong-xu-ly-anh">
<h2>11.2.2. Trích lọc đặc trưng trong xử lý ảnh<a class="headerlink" href="#trich-loc-dac-trung-trong-xu-ly-anh" title="Permalink to this headline">¶</a></h2>
<p>Trong quãng thời gian trước đây khi tài nguyên tính toán còn hạn chế và “thời kì phục hưng của mạng thần kinh” vẫn chưa thực sự quay trở lại, khai phá đặc trưng cho dữ liệu hình ảnh là một lĩnh vực phức tạp. Người ta phải thiết kế những bộ trích lọc thủ công để trích lọc các đặc trưng như góc, cạnh, đường nét ngang, dọc, chéo,… Những thuật toán như <a class="reference external" href="https://phamdinhkhanh.github.io/2019/11/22/HOG.html">HOG</a>, <a class="reference external" href="http://luthuli.cs.uiuc.edu/~daf/courses/ComputerVisionTutorial2012/EdgesOrientationHOGSIFT-2012.pdf">SHIFT</a> là phương pháp thường được sử dụng để trích lọc đặc trưng. Nhược điểm của những phương pháp này đó là tách rời bộ trích lọc đặc trưng (<em>feature extractor</em>) và bộ phân loại (<em>classifier</em>) nên mô hình có tốc độ huấn luyện và dự báo chậm.</p>
<p>Thời kì tan băng của deep learning đã khiến mạng CNN phát triển mạnh mẽ. Những kiến trúc mạng CNN hiện đại ngày càng trở nên sâu hơn và đạt độ chính xác cao. Đây là những kiến trúc end-to-end cho phép các bộ trích lọc đặc trưng gắn liền với bộ phân loại trong một pipeline duy nhất. Các bộ trích lọc cũng không cần khởi tạo một cách thủ công mà trái lại chúng được sinh ngẫu nhiên theo các phân phối giả định.</p>
<p>Nhờ các nguồn tài nguyên gồm các mô hình pretrained sẵn có mà bạn không cần phải tìm ra kiến trúc và huấn luyện mạng từ đầu. Thay vào đó, có thể tải xuống một mạng hiện đại đã được huấn luyện với trọng số từ các nguồn đã được công bố. Các nhà khoa học dữ liệu thường thực hiện điều chỉnh để thích ứng với các mạng này theo nhu cầu của họ bằng cách “tách” các lớp kết nối đầy đủ (fully connected layers) cuối cùng của mạng, thêm các lớp mới được thiết kế cho một nhiệm vụ cụ thể, và sau đó đào tạo mạng trên dữ liệu mới. Nếu nhiệm vụ của bạn chỉ là vector hóa hình ảnh, bạn chỉ cần loại bỏ các lớp cuối cùng và sử dụng kết quả đầu ra từ các lớp trước đó:</p>
<p><img alt="" src="https://camo.githubusercontent.com/ee00962051042ac56919da91c4b9d3209e6cb4f0c6fb30e80dda67e229495fca/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a49775f634b46774c6b54564f325350724f5a553272512e706e67" /></p>
<p><strong>Hình 4</strong>: Đây là một mô hình phân lớp được huấn luyện trên một bộ dữ liệu từ trước hay còn gọi là mô hình pretrained. Lớp cuối cùng của mạng được tách ra và sử dụng để huấn luyện lại trên tập dữ liệu mới nhằm điều chỉnh để dự báo cho bộ dữ liệu mới.</p>
<p>Tuy nhiên, chúng ta sẽ không tập trung quá nhiều vào kỹ thuật mạng nơ ron. Thay vào đó các feature được tạo thủ công vẫn rất hữu ích: ví dụ đối với bài toán trong cuộc thi <a class="reference external" href="https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries">Rental Listing Inquiries - Kaggle Competition</a>, để dự đoán mức độ phổ biến của danh sách cho thuê, ta có thể giả định rằng các căn hộ có ánh sáng sẽ thu hút nhiều sự chú ý hơn và tạo một feature mới như “giá trị trung bình của pixel”.</p>
<p><strong>Trích lọc thông tin văn bản trên hình ảnh</strong></p>
<p><em>OCR</em> (<em>Optical character recognition</em>) là dạng bài toán trích lọc thông tin văn bản trên hình ảnh. Chúng có tính ứng dụng cao và thường mang lại nhiều thông tin khi xử lý dữ liệu dạng hình ảnh.</p>
<p>Chằng hạn nếu có văn bản trên hình ảnh, bạn có thể đọc nó để khai thác một số thông tin thông qua gói phát hiện văn bản trong hình ảnh <a class="reference external" href="https://github.com/madmaze/pytesseract">pytesseract</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">script</span> echo skipping
!sudo apt-get install tesseract-ocr
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1">##### Just a random picture from search</span>
<span class="n">img</span> <span class="o">=</span> <span class="s1">&#39;http://ohscurrent.org/wp-content/uploads/2015/09/domus-01-google.jpg&#39;</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">content</span><span class="p">))</span>

<span class="c1"># show image</span>
<span class="n">img_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img_arr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Đọc một hình ảnh thiết kế căn hộ thông qua link.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">script</span> echo skipping
import cv2
from PIL import Image
import pytesseract

img_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)
print(image_to_string(img_rgb))
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="thong-tin-dia-ly">
<h2>11.2.3. Thông tin địa lý<a class="headerlink" href="#thong-tin-dia-ly" title="Permalink to this headline">¶</a></h2>
<p>Trong python chúng ta có một package khá phổ biến trong việc khai thác các thông tin địa lý đó là <code class="docutils literal notranslate"><span class="pre">reverse_geocoder</span></code>. Có 2 dạng bài toán chính với thông tin địa lý gồm</p>
<ul class="simple">
<li><p>geocoding: mã hóa một tọa độ địa lý từ một địa chỉ.</p></li>
<li><p>revert geocoding: từ thông tin cung cấp về kinh độ và vĩ độ trả về địa chỉ của địa điểm và các thông tin có liên quan.</p></li>
</ul>
<p>Cả hai bài toán đều có thể giải quyết thông qua API của google map hoặc OpenStreetMap. Sau đây là ví dụ trích xuất thông tin địa lý từ một địa điểm thông qua kinh độ và vĩ độ.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">script</span> echo skipping
# install package reverse_geocoder
!pip install reverse_geocoder
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">reverse_geocoder</span> <span class="k">as</span> <span class="nn">revgc</span>

<span class="c1"># truyền vào latitude, longitude</span>
<span class="n">revgc</span><span class="o">.</span><span class="n">search</span><span class="p">((</span><span class="mf">21.0364466</span><span class="p">,</span> <span class="mf">105.8450788</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Như chúng ta thấy, từ tọa độ có thể biết được căn hộ này nằm ở quận Hoàn Kiếm, Hà Nội, là một nơi phát triển và có mức sống cao. Như vậy mức giá của nó khả năng sẽ cao hơn. Từ quận và huyện ta xác định được căn hộ có nằm ở trung tâm hay không, các tiện nghi xung quan nó. Những thông tin trên rất quan trọng trong việc đánh giá khả năng bán được của căn hộ. Mặc dù trong bộ dữ liệu gốc không hề xuất hiện nhưng chúng có thể được trích xuất từ tọa độ địa lý.</p>
</div>
<div class="section" id="du-lieu-thoi-gian">
<h2>11.2.4. Dữ liệu thời gian<a class="headerlink" href="#du-lieu-thoi-gian" title="Permalink to this headline">¶</a></h2>
<p>Trong dự báo, các dữ liệu thường có trạng thái thay đổi. Trạng thái của ngày hôm qua có thể khác biệt so với ngày hôm nay. Chẳng hạn như chiều cao, cân nặng của một người hay giá thị trường của các cổ phiếu. Chính vì thế thời gian là một thông tin có ảnh hưởng lớn tới biến mục tiêu. Từ một mốc thời gian biết trước chúng ta có thể phân rã thông tin thành giờ trong ngày, ngày trong tháng, tháng, quí, năm,… Sẽ có rất nhiều điều thú vị được khám phá từ các thông tin này. Chẳng hạn như các qui luật của một số chuỗi số thay đổi theo mùa vụ: Nhiệt độ các tháng thay đổi theo mùa, GDP thay đổi theo qui luật quí, doanh số tiêu thụ kem thay đổi theo mùa,… Yếu tố thời gian còn giúp xác định xu hướng biến đổi của một biến theo thời gian và kết hợp với tính mùa vụ sẽ trở thành một chỉ số quan trọng để ước lượng chuỗi thời gian.</p>
<p>Biến đổi one-hot coding là một phương pháp quan trọng được sử dụng để mã hóa các biến chu kì thời gian. One-hot coding sẽ biến đổi một biến thành các vector có phần tử là 0 hoặc 1, trong đó 1 đại diện cho sự xuất hiện của đặc trưng và 0 đại diện cho các đặc trưng mà biến không có.</p>
<p>Ví dụ: Chúng ta có 1 ngày trong tuần có thể rơi vào các thứ từ 2 đến chủ nhật. Như vậy một biểu diễn one-hot encoding của ngày thứ 2 sẽ là một véc tơ có phần tử đầu tiên bằng 1 và các phần tử còn lại bằng 0. Biểu diễn này cũng tương tự như với mã hóa dữ liệu văn bản thành các <em>sparse vector</em>.</p>
<p>Trong python chúng ta có thể sử dụng hàm weekday() để xác định thứ tự của một ngày trong tuần. Thuộc tính weekday() chỉ tồn tại đối với dữ liệu dạng datetime. Do đó ta cần chuyển đổi các biến ngày đang ở dạng string về dạng datetime thông qua strftime (string format time). Bảng string format time có thể xem <a class="reference external" href="https://strftime.org/">tại đây</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;created&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;2021-08-13 00:00:00&#39;</span><span class="p">,</span> <span class="s1">&#39;2021-08-12 00:00:00&#39;</span><span class="p">,</span> <span class="s1">&#39;2021-08-11 00:00:00&#39;</span><span class="p">,</span> 
                                    <span class="s1">&#39;2021-08-10 00:00:00&#39;</span><span class="p">,</span> <span class="s1">&#39;2021-08-09 00:00:00&#39;</span><span class="p">,</span> <span class="s1">&#39;2021-08-08 00:00:00&#39;</span><span class="p">,</span> <span class="s1">&#39;2021-08-07 00:00:00&#39;</span><span class="p">]})</span>

<span class="k">def</span> <span class="nf">parser</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># Để biết được định dạng strftime của một chuỗi kí tự ta phải tra trong bàng string format time</span>
    <span class="k">return</span> <span class="n">datetime</span><span class="o">.</span><span class="n">strptime</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1"> %H:%M:%S&#39;</span><span class="p">)</span>

<span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;created&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;created&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">parser</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;created&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dtypes</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Như vậy biến created đã được chuyển về dạng datetime. Chúng ta có thể tạo ra một one-hot encoding dựa vào hàm weekday().</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;weekday&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;created&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">date</span><span class="p">()</span><span class="o">.</span><span class="n">weekday</span><span class="p">())</span>
<span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;weekday&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Ta có thể tạo ra một biến trả về trạng thái ngày có phải là cuối tuần bằng kiểm tra weekday() có rơi vào [5, 6] là những ngày cuối tuần hay không.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;is_weekend&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;created&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">date</span><span class="p">()</span><span class="o">.</span><span class="n">weekday</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;is_weekend&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Trong một số bài toán dữ liệu có thể bị phụ thuộc vào thời gian. Chẳng hạn như lịch trả nợ của thẻ tín dụng sẽ rơi vào kì sao kê là một ngày cụ thể trong tháng. Khi làm việc với dữ liệu chuỗi thời gian chúng ta nên lưu ý tới danh sách các ngày đặc biệt trong năm như nghỉ tết âm lịch, quốc khánh, quốc tế lao động,… Bởi những ngày này thường sẽ có biến động lớn về dữ liệu kinh doanh.</p>
</div>
<div class="section" id="du-lieu-tu-website-log">
<h2>11.2.5. Dữ liệu từ website, log<a class="headerlink" href="#du-lieu-tu-website-log" title="Permalink to this headline">¶</a></h2>
<p>Các hệ thống website lớn sẽ tracking lại các session của người dùng. Những thông tin được tracking bao gồm thông tin thiết bị, loại event, customer ID, … Từ customer ID chúng có thể link tới database người dùng để biết được các thông tin về giới tính, độ tuổi, tài khoản, hành vi giao dịch,… Trong một số trường hợp một khách hàng có thể thay đổi thiết bị truy cập, do đó không phải hầu hết các trường hợp chúng ta đều map được session với Customer ID trên dữ liệu local. Tuy nhiên từ các thông tin được lưu trong Cookie về người dùng (còn gọi là user agent) cũng cung cấp cho chúng ta khá nhiều điều. Chẳng hạn như: Thiết bị truy cập, trình duyệt, hệ điều hành,… Từ thiết bị di động chúng ta cũng ước đoán được người dùng có mức thu nhập như thế nào: Sử dụng Iphone X thì khả năng cao là người có thu nhập cao, sử dụng điện thoại xiaomi khả năng là người thu nhập trung bình và thấp,… Để phân loại các thông tin về người dùng chúng ta có thể sử dụng package user_agents trong python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">script</span> echo skipping
!pip install user_agents
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">user_agents</span>
<span class="c1"># Giả định có một user agent như bên dưới</span>
<span class="n">ua</span> <span class="o">=</span> <span class="s1">&#39;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/56.0.2924.76 Chrome/56.0.2924.76 Safari/537.36&#39;</span>
<span class="c1"># Parser thông tin user agent</span>
<span class="n">ua</span> <span class="o">=</span> <span class="n">user_agents</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">ua</span><span class="p">)</span>
<span class="c1"># Khai thác các thuộc tính của user</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Is a bot? &#39;</span><span class="p">,</span> <span class="n">ua</span><span class="o">.</span><span class="n">is_bot</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Is mobile? &#39;</span><span class="p">,</span> <span class="n">ua</span><span class="o">.</span><span class="n">is_mobile</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Is PC? &#39;</span><span class="p">,</span><span class="n">ua</span><span class="o">.</span><span class="n">is_pc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;OS Family: &#39;</span><span class="p">,</span><span class="n">ua</span><span class="o">.</span><span class="n">os</span><span class="o">.</span><span class="n">family</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;OS Version: &#39;</span><span class="p">,</span><span class="n">ua</span><span class="o">.</span><span class="n">os</span><span class="o">.</span><span class="n">version</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Browser Family: &#39;</span><span class="p">,</span><span class="n">ua</span><span class="o">.</span><span class="n">browser</span><span class="o">.</span><span class="n">family</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Browser Version: &#39;</span><span class="p">,</span><span class="n">ua</span><span class="o">.</span><span class="n">browser</span><span class="o">.</span><span class="n">version</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="id2">
<h1>11.3. Biến đổi đặc trưng (feature transformation)<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h1>
<p>Các chiều dữ liệu thường có sự khác biệt về đơn vị (<em>scale</em>) và phân phối (<em>distribution</em>) và điều đó gây ảnh hưởng tới mô hình ở những khía cạnh sau:</p>
<ul class="simple">
<li><p>Khi huấn luyện thường dẫn tới hiện tượng <em>bùng nổ gradient</em> (<em>exploding gradient</em>). Hiện tượng <em>bùng nổ gradient</em> là một hiện tượng phổ biến khiến cho giá trị dự báo bị quá lớn (thường là giá trị <em>nan</em>).</p></li>
<li><p>Không chuẩn hoá dữ liệu đầu vào có thể khiến cho quá trình huấn luyện thiếu ổn định và có thể không vượt qua được các <em>điểm cực trị địa phương</em> để đi tới <em>cực trị toàn cục</em>.</p></li>
<li><p>Giá trị dự báo của biến mục tiêu trở nên nhạy cảm hơn. Đối với những biến có đơn vị lớn và trọng số huấn luyện lớn thì một sự thay đổi nhỏ về giá trị của biến sẽ dẫn tới sự thay đổi lớn của giá trị dự báo.</p></li>
</ul>
<p>Trong quá trình huấn luyện mô hình, sử dụng các phép biến đổi dữ liệu sẽ luôn giúp ích cho mô hình huấn luyện. Xin trích dẫn:</p>
<p>“In practice it is nearly always advantageous to apply pre-processing transformations to the input data before it is presented to a network. Similarly, the outputs of the network are often post-processed to give the required output values.”</p>
<p>Page 296, <a class="reference external" href="https://www.amazon.com/Networks-Recognition-Advanced-Econometrics-Paperback/dp/0198538642/ref=as_li_ss_tl?ie=UTF8&amp;qid=1540160671&amp;sr=8-2&amp;keywords=Neural+Networks+for+Pattern+Recognition&amp;linkCode=sl1&amp;tag=inspiredalgor-20&amp;linkId=991aca4ff0fc6769d5dad40a86092458&amp;language=en_US">Neural Networks for Pattern Recognition</a>, 1995.</p>
<p>Có hai phương pháp chính để biến đổi dữ liệu đó là <em>scaling</em> và <em>chuẩn hoá</em> (<em>standardize</em>) mà ta sẽ tìm hiểu bên dưới.</p>
<div class="section" id="chuan-hoa-standardization">
<h2>11.3.1. Chuẩn hoá (<em>standardization</em>)<a class="headerlink" href="#chuan-hoa-standardization" title="Permalink to this headline">¶</a></h2>
<p>Kĩ thuật <em>chuẩn hoá</em> được áp dụng đối với những biến không có phân phối chuẩn. Biến được biến đổi theo kì vọng và độ lệch chuẩn như sau:</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}' = \frac{\mathbf{x}-\overline{\mathbf{x}}}{\sigma(\mathbf{x})}\]</div>
<p>Từ đó suy ra giá trị của biến sau khi biến đổi ngược lại:</p>
<div class="math notranslate nohighlight">
\[\mathbf{x} = \mathbf{x}'*\sigma(\mathbf{x})+\bar{\mathbf{x}}\]</div>
<p>Các biến sau khi được chuẩn hoá sẽ có cùng một dạng phân phối chuẩn hoá với trung bình bằng 0 và phương sai bằng 1. Nhờ đó quá trình huấn luyện sẽ trở nên ổn định và hội tụ tới nghiệm tối ưu nhanh hơn.</p>
<p><img alt="" src="https://i.imgur.com/Kql3MEH.jpeg" /></p>
<p><strong>Hình 5</strong>: Phương pháp <em>chuẩn hoá</em> (<em>standardization</em>). Sau chuẩn hoá biến có phần phối chuẩn với trung bình bằng 0 và phương sai bằng 1.</p>
<p>Ngoài ra ta còn chứng minh được rằng phương pháp <em>chuẩn hoá</em> còn là một phép co trong không gian mà ở đó khoảng cách giữa 2 điểm bất kì luôn cùng một tỷ lệ so với không gian gốc.</p>
<p>Thật vậy. Giả sử ta xét hai điểm là <span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span> và <span class="math notranslate nohighlight">\(\mathbf{x}_2\)</span> trong không gian gốc. Toạ độ hai điểm này sau khi MinMax Scaling lần lượt là <span class="math notranslate nohighlight">\(\mathbf{x}_1'\)</span> và <span class="math notranslate nohighlight">\(\mathbf{x}_2'\)</span>. Chúng có mối liên hệ với giá trị gốc theo phương trình:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\mathbf{x}_1 &amp; = &amp; \mathbf{x}_{1}' * \sigma(\mathbf{x}) + \bar{\mathbf{x}}  \\
\mathbf{x}_2 &amp; = &amp; \mathbf{x}_{2}' * \sigma(\mathbf{x}) + \bar{\mathbf{x}}
\end{eqnarray}\end{split}\]</div>
<p>Suy ra:</p>
<div class="math notranslate nohighlight">
\[\frac{\mathbf{x}_1-\mathbf{x}_2}{\mathbf{x}_1' - \mathbf{x}_2'} = \sigma(\mathbf{x}) = \alpha\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Khởi tạo một biến X ngẫu nhiên</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">6</span> <span class="o">+</span> <span class="mi">5</span>
<span class="c1"># Standardization</span>
<span class="n">X_std</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">_plot_dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">varname</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">):</span>
  <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">bins</span><span class="p">,</span> <span class="n">kde</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;histogram of </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">varname</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">varname</span><span class="p">])</span>


<span class="c1"># Visualization</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">ax_1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax_1</span> <span class="o">=</span> <span class="n">_plot_dist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="n">varname</span><span class="o">=</span><span class="s1">&#39;original data&#39;</span><span class="p">)</span>


<span class="n">ax_2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax_2</span> <span class="o">=</span> <span class="n">_plot_dist</span><span class="p">(</span><span class="n">X_std</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="n">varname</span><span class="o">=</span><span class="s1">&#39;standardized data&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Hình 5:</strong> Biến bên trái chưa được chuẩn hoá, khoảng biến thiên của biến trong khoảng từ -15 đến 20 và trung bình là 5. Sau khi chuẩn hoá ta thu được biến bên phải có phân phối chuẩn với trung bình là 0 và khoảng biến thiên từ -2 tới 2. Như vậy chuẩn hoá theo phân phối chuẩn đã giúp giảm độ lớn trung bình và phương sai của biến.</p>
</div>
<div class="section" id="ki-thuat-scaling">
<h2>11.3.2. Kĩ thuật scaling<a class="headerlink" href="#ki-thuat-scaling" title="Permalink to this headline">¶</a></h2>
<p>Đối với kĩ thuật <em>scaling</em> thì chúng ta thường áp dụng trên những biến đã tuân theo phân phối chuẩn. Thông qua <em>scaling</em>, toàn bộ giá trị của biến sẽ được đưa về một miền giá trị bị giới hạn trong khoảng <span class="math notranslate nohighlight">\([0, 1]\)</span>. Khi đó đối với các điểm outliers xuất hiện trên tập <em>kiểm tra</em> (<em>test dataset</em>) thì giá trị của chúng có thể nằm ngoài miền này (tức tồn tại giá trị lớn hơn 1 và nhỏ hơn 0). Dựa trên kĩ thuật <em>scaling</em> chúng ta sẽ cân nhắc thiết lập lại outliers về các điểm đầu mút của miền giới hạn.</p>
<p>Trong kĩ thuật scaling thì chúng ta có các phương pháp chính:</p>
<div class="section" id="minmax-scaling">
<h3>11.3.2.1. Minmax Scaling<a class="headerlink" href="#minmax-scaling" title="Permalink to this headline">¶</a></h3>
<p>Biến được đưa về các range [0,1] theo công thức:</p>
<div class="math notranslate nohighlight">
\[\mathbf{x'} = \frac{\mathbf{x}-\min({\mathbf{x})}}{\max({\mathbf{x}}) - \min({\mathbf{x}})}\]</div>
<p>Như vậy giá trị của biến sau khi biến đổi ngược lại từ scaling sẽ là:</p>
<div class="math notranslate nohighlight">
\[\mathbf{x} = \mathbf{x}' * (\max(\mathbf{x}) - \min(\mathbf{x})) + \min(\mathbf{x})\]</div>
<p>MinMax Scaling còn là một phép co trong không gian mà ở đó tỷ lệ khoảng cách giữa 2 điểm bất kì được bảo toàn so với khoảng cách của chúng trong không gian gốc.</p>
<p>Thật vậy. Giả sử ta xét hai điểm là <span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span> và <span class="math notranslate nohighlight">\(\mathbf{x}_2\)</span> trong không gian gốc. Toạ độ hai điểm này sau khi MinMax Scaling lần lượt là <span class="math notranslate nohighlight">\(\mathbf{x}_1'\)</span> và <span class="math notranslate nohighlight">\(\mathbf{x}_2'\)</span>. Chúng có mối liên hệ với giá trị gốc theo phương trình:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\mathbf{x}_1 &amp; = &amp; \mathbf{x}_{1}' * (\max(\mathbf{x}) - \min(\mathbf{x})) + \min(\mathbf{x}) \\
\mathbf{x}_2 &amp; = &amp; \mathbf{x}_{2}' * (\max(\mathbf{x}) - \min(\mathbf{x})) + \min(\mathbf{x}) 
\end{eqnarray}\end{split}\]</div>
<p>Suy ra:</p>
<div class="math notranslate nohighlight">
\[\frac{\mathbf{x}_1-\mathbf{x}_2}{\mathbf{x}_1' - \mathbf{x}_2'} = \max(\mathbf{x}) - \min(\mathbf{x}) = \alpha\]</div>
<p><img alt="" src="https://i.imgur.com/Txn9nAD.jpeg" /></p>
<p><strong>Hình 6</strong>: Hình minh hoạ phương pháp MinMax Scaling.</p>
<p>Trên sklearn để thực hiện MinMaxScaler như sau:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Khởi tạo một biến X ngẫu nhiên</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="mi">5</span>
<span class="c1"># minmax scaler của X</span>
<span class="n">X_minmax</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">_plot_dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">varname</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">):</span>
  <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">bins</span><span class="p">,</span> <span class="n">kde</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;histogram of </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">varname</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">varname</span><span class="p">])</span>


<span class="c1"># Visualization</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">ax_1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax_1</span> <span class="o">=</span> <span class="n">_plot_dist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">varname</span><span class="o">=</span><span class="s1">&#39;original data&#39;</span><span class="p">)</span>

<span class="n">ax_2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax_2</span> <span class="o">=</span> <span class="n">_plot_dist</span><span class="p">(</span><span class="n">X_minmax</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">varname</span><span class="o">=</span><span class="s1">&#39;minmax scaling data&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Hình 7</strong>: Bên trái là biến gốc có giá trị nằm trong khoảng từ 2 đến 8. Sau khi chuẩn hoá MinMax Scaling thì giá trị của biến thu hẹp về miền <span class="math notranslate nohighlight">\([0, 1]\)</span>.</p>
</div>
<div class="section" id="unit-length">
<h3>11.3.2.2. Unit Length<a class="headerlink" href="#unit-length" title="Permalink to this headline">¶</a></h3>
<p>Theo phương pháp này giá trị của biến sẽ được chuẩn hoá bằng cách chia cho norm chuẩn <span class="math notranslate nohighlight">\(L_2\)</span>.</p>
<div class="math notranslate nohighlight">
\[\mathbf{x'} = \frac{\mathbf{x}}{||\mathbf{x}||_2}\]</div>
<p>Khi đó trong không gian Euclidean thì biến <span class="math notranslate nohighlight">\(\mathbf{x}'\)</span> sẽ là một véc tơ có độ dài là 1 đơn vị. Chính vì vậy phương pháp chuẩn hoá này còn gọi là chuẩn hoá <em>độ dài đơn vị</em> (<em>Unit Length</em>). Ta cũng dễ dàng nhận thấy các giá trị sau khi chuẩn hoá theo <em>Unit Length</em> sẽ nằm trong khoảng <span class="math notranslate nohighlight">\([0, 1]\)</span>. So với các phương pháp chuẩn hoá khác như <em>Standardization</em> và <em>MinMax Scaling</em> thì chuẩn hoá theo <em>Unit Length</em> thường có mức độ thu hẹp độ biến động của biến là lớn nhất. Dường như biến sẽ bị co cụm về một miền giá trị rất nhỏ gần 0. Chúng ta có thể kiểm chứng điều này thông qua ví dụ về chuẩn hoá <em>Unit Length</em> trên sklearn bên dưới:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Khởi tạo một biến X ngẫu nhiên</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="mi">5</span>
<span class="c1"># Unit Length scaling</span>
<span class="n">X_un</span> <span class="o">=</span> <span class="n">X</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_plot_dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">varname</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">):</span>
  <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">bins</span><span class="p">,</span> <span class="n">kde</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;histogram of </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">varname</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">varname</span><span class="p">])</span>

<span class="c1"># Visualization</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">ax_1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax_1</span> <span class="o">=</span> <span class="n">_plot_dist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">varname</span><span class="o">=</span><span class="s1">&#39;original data&#39;</span><span class="p">)</span>

<span class="n">ax_2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax_2</span> <span class="o">=</span> <span class="n">_plot_dist</span><span class="p">(</span><span class="n">X_un</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">varname</span><span class="o">=</span><span class="s1">&#39;unit length scaling data&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Hình 8</strong>: Bên trái là phân phối của biến gốc và bên phải là phân phối của biến sau khi thực hiện <em>Unit Length</em> scaling. So với các phương pháp phân phối khác thì <em>Unit Length</em> trả về giá trị có khoảng biến thiên hẹp hơn và gần sát với 0.</p>
</div>
<div class="section" id="robust-scaling">
<h3>11.3.2.3. Robust Scaling<a class="headerlink" href="#robust-scaling" title="Permalink to this headline">¶</a></h3>
<p>Trong trường hợp dữ liệu tồn tại outliers thì các phương pháp chuẩn hoá dựa trên <em>Standardization</em>, <em>MinMax Scaling</em> sẽ thường không mang lại hiệu quả. Sự xuất hiện của các outliers thường nằm ở rìa phân phối của biến và chúng có xác suất xảy ra thấp. Điều đó khiến cho phân phối bị lệch sang một bên (hiện tượng <em>skewness</em> cao) và sử dụng các phương pháp chuẩn hoá thông thường như <em>Standardization</em> trở nên khó khăn hơn do bản thân trung bình và độ lệch chuẩn được tính ra cũng đã bị méo bởi sự xuất hiện của những điểm outliers.</p>
<p>Một trong những cách tiếp cận để chuẩn hoá dữ liệu khi xuất hiện outliers đó là loại bỏ outliers khỏi tính toán trung bình và độ lệch chuẩn, sau đó sử dụng những giá trị được tính toán để <em>scaling</em> biến.</p>
<p>Phương pháp này chính là <em>Robust Scaler</em>. Chúng được thực hiện bằng cách tính toán các khoảng phân vị trung vị <span class="math notranslate nohighlight">\(Q_2\)</span> (50% percentile), và các khoảng phân vị <span class="math notranslate nohighlight">\(Q_1\)</span> (25% percentile), phân vị <span class="math notranslate nohighlight">\(Q_3\)</span> (75% percentile). Giá trị của một biến sẽ được trừ đi trung vị <span class="math notranslate nohighlight">\(Q_2\)</span> và sau đó chia cho độ dài <em>khoảng liên phân vị</em> <em>(interquartile range - IQR</em>,<span class="math notranslate nohighlight">\(~\text{IQR} = Q_3 - Q_1\)</span>). Công thức như sau:</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}' = \frac{\mathbf{x}-Q_2(\mathbf{x})}{Q_3(\mathbf{x})-Q_1(\mathbf{x})}\]</div>
<p>Sử dụng <em>Robust Scaler</em> có thể giúp loại bỏ các <em>outliers</em> và sau đó chúng ta có thể tiếp tục thực hiện các phương pháp chuẩn hoá khác sau đó như <em>Standardization</em>, <em>MinMax Scaling</em>.</p>
<p>Phương pháp <em>Robust Scaler</em> được phát triển trong sklearn thông qua class RobustScaler:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sklearn</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">RobustScaler</span><span class="p">(</span>
<span class="n">with_centering</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="n">with_scaling</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="n">quantile_range</span><span class="o">=</span><span class="p">(</span><span class="mf">25.0</span><span class="p">,</span> <span class="mf">75.0</span><span class="p">),</span>
<span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Trong đó:</p>
<ul class="simple">
<li><p><em>with_centering</em>: Quyết định xem giá trị có được chuẩn hoá bằng cách trừ đi <span class="math notranslate nohighlight">\(Q_2\)</span>. Mặc định là True.</p></li>
<li><p><em>with_scaling</em>: Có thực hiện scale bằng cách chia cho <span class="math notranslate nohighlight">\(\text{IQR}\)</span> hay không ? Mặc định được thiết lập là True.</p></li>
</ul>
<p>Chúng ta có thể thay đổi độ dài khoảng <span class="math notranslate nohighlight">\(\text{IQR}\)</span> thông qua thay đổi giá trị của đối số <em>quantile_range</em>. Nó nhận giá trị là một khoảng là tập con của <span class="math notranslate nohighlight">\([0, 100]\)</span>. Thay đổi giá trị này sẽ thay đổi định nghĩa về outlier và độ lớn scaling.</p>
<p>Tiếp theo chúng ta sẽ phân tích kĩ hơn về <em>Robust Scaler</em> thông qua ví dụ bên dưới.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
  
<span class="c1"># data</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="c1"># Distribution with lower outliers</span>
    <span class="s1">&#39;x1&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">25</span><span class="p">)]),</span>
    <span class="c1"># Distribution with higher outliers</span>
    <span class="s1">&#39;x2&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">90</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">25</span><span class="p">)]),</span>
<span class="p">})</span>
  
<span class="c1"># robust scaler  </span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>
<span class="n">robust_df</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">robust_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">robust_df</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">])</span>

<span class="c1"># standard scaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">standard_df</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">standard_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">standard_df</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">])</span>

<span class="c1"># minmax scaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">minmax_df</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">minmax_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">minmax_df</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">])</span>

<span class="c1"># visualization</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Before Scaling&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">])</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;After Robust Scaling&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span> 
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">robust_df</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">robust_df</span><span class="p">[</span><span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">])</span>

<span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;After Standard Scaling&#39;</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">standard_df</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax3</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">standard_df</span><span class="p">[</span><span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax3</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="s1">&#39;b&#39;</span> <span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">])</span>

<span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;After MinMax Scaling&#39;</span><span class="p">)</span>
<span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">minmax_df</span><span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax4</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">minmax_df</span><span class="p">[</span><span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax4</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax4</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Hình 9</strong>: Đồ thị so sánh các phương pháp chuẩn hoá khác nhau là <em>Robust Scaling</em>, <em>Standardization</em> và <em>MinMax Scaling</em>. Biến <span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span> xuất hiện outliers ở các gía trị thấp trong khi biến <span class="math notranslate nohighlight">\(\mathbf{x}_2\)</span> xuất hiện outliers ở các giá trị cao. Chúng ta có thể thấy phân phối của biến bị lệch hẳn sang một bên đối với phương pháp <em>MinMax Scaling</em>.  Phương pháp <em>Standardization</em> thì do ảnh hưởng của outliers nên các phân phối sẽ bị lệch trái hoặc lệch phải chứ không hoàn toàn đối xứng qua điểm 0. Trong khi đó <em>Robust Scaling</em> do đã loại bỏ được ảnh hưởng của outliers nên trả về kết quả phân phối đối xứng qua 0.</p>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="id3">
<h1>11.4. Lựa chọn đặc trưng (<em>feature selection</em>)<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h1>
<p>Để xây dựng mô hình chúng ta sẽ rất cần đến dữ liệu lớn. Nhưng dữ liệu quá lớn cũng không thực sự tốt. Những hệ thống của các tập đoàn công nghệ lớn có thể có số lượng trường dữ liệu lên tới hàng trăm ngàn. Đây là một con số khổng lồ và sẽ gây ra những hạn chế đó là:</p>
<ul class="simple">
<li><p>Tăng chi phí tính toán.</p></li>
<li><p>Quá nhiều biến giải thích có thể dẫn tới <em>quá khớp</em> (<em>overfiting</em>). Tức hiện tượng mô hình hoạt động tốt trên <em>tập huấn luyện</em> nhưng kém trên <em>tập kiểm tra</em>.</p></li>
<li><p>Trong số các biến sẽ có những biến gây nhiễu và làm giảm chất lượng mô hình.</p></li>
<li><p>Rối loạn thông tin do không thể kiểm soát và hiểu hết các biến.</p></li>
</ul>
<p>Chính vì thế chúng ta cần phải có những phương pháp như giảm chiều dữ liệu hoặc lựa chọn biến quan trọng. Về phương pháp giảm chiều dữ liệu sẽ được trình bày ở một chương khác. Trong chương này này chúng ta sẽ làm quen với một số kĩ thuật lựa chọn biến thông dụng.</p>
<p>Bên dưới là những thuật toán quan trọng được sử dụng để lựa chọn các biến.</p>
<div class="section" id="phuong-phap-thong-ke">
<h2>11.4.1. Phương pháp thống kê<a class="headerlink" href="#phuong-phap-thong-ke" title="Permalink to this headline">¶</a></h2>
<p>Một phương pháp quan trọng trong các phương pháp thống kê nhằm giảm số lượng biến là lựa chọn dựa trên phương sai. Dựa trên phân tích các biến không biến động thì không có tác dụng gì trong việc phân loại hoặc dự báo bởi chúng ta dường như đã biết được giá trị của chúng cho tất cả các quan sát. Do đó ý tưởng chính của phương pháp này là thông qua độ lớn phương sai của toàn bộ các <em>biến numeric</em> để loại bỏ những biến nếu nó nhỏ hơn một ngưỡi nhất định.</p>
<p>Trong sklearn chúng ta có thể sử dụng <em>VarianceThreshold</em> để lọc bỏ biến theo phương sai.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">VarianceThreshold</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>

<span class="c1"># Khởi toạo dữ liệu example</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X shape:&#39;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y shape:&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Lọc bỏ các biến có phương sai nhỏ hơn 0.8</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total features with thres=0.8: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">VarianceThreshold</span><span class="p">(</span><span class="mf">0.8</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="c1"># Lọc bỏ các biến có phương sai nhỏ hơn 1.0</span>
<span class="n">X_kvar</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total features with thres=1.0: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_kvar</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Ngoài phương pháp phương sai, chúng ta có thể áp dụng <a class="reference external" href="https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection">kiểm định thống kê đơn biến</a>. Phương pháp này sẽ đánh giá sự độc lập tuyến tính giữa hai biến ngẫu nhiên dựa trên phân phối <em>chi-squared</em> và <em>Fisher</em> để lựa chọn ra <span class="math notranslate nohighlight">\(k\)</span> biến tốt nhất. Để hình dung kĩ hơn về hai phương pháp thống kê nêu trên, tiếp theo chúng ta cùng thực hành lựa chọn biến và đánh giá hiệu quả mô hình.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="c1"># Lựa chọn biến dựa trên phương pháp Fisher</span>
<span class="n">X_kbest</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X shape after applying statistical selection: &#39;</span><span class="p">,</span><span class="n">X_kbest</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Chúng ta sẽ cùng đánh giá hiệu quả mô hình bằng cross-validation trước và sau lựa chọn biến với KFold = 5.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hồi qui logistic</span>
<span class="n">logit</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Cross validation cho:</span>
<span class="c1"># 1.dữ liệu gốc</span>
<span class="n">acc_org</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="c1"># 2. Áp dụng phương sai</span>
<span class="n">acc_var</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">X_kvar</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="c1"># 3. Áp dụng phương pháp thống kê</span>
<span class="n">acc_stat</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">X_kbest</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy trên dữ liệu gốc:&#39;</span><span class="p">,</span> <span class="n">acc_org</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy áp dụng phương sai:&#39;</span><span class="p">,</span> <span class="n">acc_var</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy dụng pp thống kê:&#39;</span><span class="p">,</span> <span class="n">acc_stat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Như vậy ta thấy sau khi áp dụng feature selection đã cải thiện được độ chính xác của mô hình dự báo.</p>
</div>
<div class="section" id="su-dung-mo-hinh">
<h2>11.4.2. Sử dụng mô hình<a class="headerlink" href="#su-dung-mo-hinh" title="Permalink to this headline">¶</a></h2>
<p>Đây là phương pháp rất thường xuyên được áp dụng trong các cuộc thi phân tích dữ liệu. Chúng ta sẽ dựa trên một số mô hình cơ sở để đánh giá mức độ quan trọng của các biến. Có hai lớp mô hình thường được sử dụng để đánh biến đó là <em>Random Forest</em> và <em>Linear Regression</em>. Ưu điểm của các phương pháp này là kết quả đánh giá rất chuẩn xác, tuy nhiên nhược điểm của chúng là phải xây dựng mô hình hồi qui rồi mới xác định được biến quan trọng. Điều này dường như đi trái lại với thực tế phải lựa chọn biến trước khi huấn luyện mô hình. Để áp dụng phương pháp này chúng ta thực hiện như sau:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectFromModel</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="c1"># Hồi qui theo RandomForest</span>
<span class="n">rdFrt</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># Hồi qui theo LinearSVC</span>
<span class="n">lnSVC</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l1&quot;</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># Hồi qui theo Lasso</span>
<span class="n">lassoReg</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="c1"># Tạo một pipeline thực hiện lựa chọn biến từ RandomForest model và hồi qui theo logit</span>
<span class="n">pipe1</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">rdFrt</span><span class="p">),</span> <span class="n">logit</span><span class="p">)</span>
<span class="c1"># Tạo một pipeline thực hiện lựa chọn biến từ Linear SVC model và hồi qui theo logit</span>
<span class="n">pipe2</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">lnSVC</span><span class="p">),</span> <span class="n">logit</span><span class="p">)</span>

<span class="c1"># Cross validate đối với </span>
<span class="c1"># 1. Mô hình logit</span>
<span class="n">acc_log</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="c1"># 2. Mô hình RandomForest</span>
<span class="n">acc_rdf</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rdFrt</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="c1"># 3. Mô hình pipe1</span>
<span class="n">acc_pip1</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipe1</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="c1"># 3. Mô hình pipe2</span>
<span class="n">acc_pip2</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipe2</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy theo logit:&#39;</span><span class="p">,</span> <span class="n">acc_log</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy theo random forest:&#39;</span><span class="p">,</span> <span class="n">acc_rdf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy theo pipeline 1:&#39;</span><span class="p">,</span> <span class="n">acc_pip1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy theo pipeline 2:&#39;</span><span class="p">,</span> <span class="n">acc_pip2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Như vậy select dựa trên mô hình Random Forest và Linear SVC đã có hiệu quả trong việc cải thiện độ chính xác của mô hình. Bên cạnh việc thực hiện lựa chọn biến dựa trên model, chúng ta còn có thể lựa chọn biến theo grid search.</p>
</div>
<div class="section" id="su-dung-search">
<h2>11.4.3. Sử dụng Search<a class="headerlink" href="#su-dung-search" title="Permalink to this headline">¶</a></h2>
<p><strong>Exhaustive Search</strong></p>
<p>Ý tưởng chính của phương pháp này là tìm ra một tập con các đặc trưng tốt nhất trong số các đặc trưng đầu vào dựa trên một thước đo mô hình cụ thể (chẳng hạn như <em>accuracy</em>). Ví dụ, khi bạn có tổng cộng <span class="math notranslate nohighlight">\(n\)</span> đặc trưng thì bạn cần huấn luyện mô hình trên tất cả các kết hợp từ <span class="math notranslate nohighlight">\(1, 2, 3, ..., n\)</span> đặc trưng. Tổng số lượng các kết hợp có thể sẽ là:</p>
<div class="math notranslate nohighlight">
\[\binom{n}{1} + \binom{n}{2} + \binom{n}{3} + \dots + \binom{n}{n} = 2^{n} - 1\]</div>
<p>Đây là số lượng không hề nhỏ nếu bộ dữ liệu của bạn có số lượng đặc trưng lớn. Chính vì thế phương pháp này được coi là <em>Exhaustive</em> và chỉ phù hợp với những bộ dữ liệu có số lượng đặc trưng nhỏ. Ưu điểm của phương pháp này mang lại đó là giúp tìm ra được tập con đặc trưng tốt nhất trực tiếp thông qua đánh giá <em>accuracy</em>.</p>
<p><strong>Sequential Feature Selection</strong></p>
<p>Nếu như chúng ta tìm kiếm trên toàn bộ các bộ kết hợp đặc trưng đầu vào của mô hình sẽ rất lâu. Do đó việc đầu tiên ta cần thực hiện là giới hạn không gian tìm kiếm. Tuỳ theo hướng tìm kiếm là tăng biến hoặc giảm biến mà phương pháp này bao gồm hai hai lựa chọn là: forward hoặc backward tương ứng. Theo lựa chọn forward thì ban đầu ta xuất phát từ lựa chọn <span class="math notranslate nohighlight">\(1\)</span> đặc trưng đầu vào mà mô hình có kết quả tốt nhất. Ở các bước tiếp theo ta sẽ tìm ra một đặc trưng phù hợp nhất để thêm vào mô hình sao cho thước đo đánh giá mô hình là lớn nhất. Quá trình này tiếp tục cho đến khi số lượng các đặc trưng được thêm vào đạt mức tối đa <code class="docutils literal notranslate"><span class="pre">k_features</span></code> hoặc tới khi hàm loss fuction mô hình không giảm nữa. Theo chiều ngược lại, bắt đầu từ toàn bộ các đặc trưng và loại dần đặc trưng thì sẽ là backward.</p>
<p>So với phương pháp <em>Exhaustive Search</em> thì <em>Sequential Feature Selection</em> ít tốn kém hơn về chi phí nhưng không đảm bảo chắc chắn rằng tập hợp đặc trưng tìm được là tối ưu. Hướng di chuyển tìm kiếm theo forward và backward cũng hoàn toàn là lựa chọn may rủi.</p>
<p>Bên dưới ta sẽ tiến hành áp dụng phương pháp <em>Sequential Feature Selection</em> để tìm kiếm đặc trưng theo backward với số biến cần lựa chọn là <code class="docutils literal notranslate"><span class="pre">k_features=3</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">script</span> echo skipping
!pip install mlxtend
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlxtend.feature_selection</span> <span class="kn">import</span> <span class="n">SequentialFeatureSelector</span>

<span class="n">selector</span> <span class="o">=</span> <span class="n">SequentialFeatureSelector</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> 
                                     <span class="n">verbose</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> 
                                     <span class="n">k_features</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                                     <span class="n">forward</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                     <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">selector</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Ta có thể thấy mô hình xuất phát từ 50 biến ban đầu và sau mỗi một quá trình sẽ loại dần các biến cho đến khi số lượng biến tối thiểu đạt được là 3. Sau mỗi quá trình mức độ accuracy sẽ tăng dần.</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="tong-ket">
<h1>11.5. Tổng kết<a class="headerlink" href="#tong-ket" title="Permalink to this headline">¶</a></h1>
<p>Như vậy sau bài này các bạn đã nhận ra được <em>Feature Engineering</em> quan trọng như thế nào trong việc tạo ra một mô hình dự báo có sức mạnh. Tổng hợp lại các phương pháp feature engineering:</p>
<ol class="simple">
<li><p>Trích lọc đặc trưng: Ứng dụng trong deep learning như xử lý ảnh và xử lý ngôn ngữ tự nhiên, phân rã thời gian, làm việc với dữ liệu địa lý, dữ liệu người dùng tracking từ các hệ thống web, app.</p></li>
<li><p>Biến đổi đặc trưng: Minmax scaling, Unit length scaling, Standardization, Robust Scaling.</p></li>
<li><p>Lựa chọn đặc trưng: Sử dụng phương pháp thống kê, mô hình hoặc grid search.</p></li>
</ol>
<p>Câu hỏi đặt ra:</p>
<blockquote>
<div><p>Bên cạnh những thuật toán, modeler có cần kiến thức về lĩnh vực chuyên ngành (<em>knowledge domain</em>) không?</p>
</div></blockquote>
<p>Để xây dựng một mô hình tốt không chỉ cần có kiến thức về mô hình mà các hiểu biết về lĩnh vực chuyên ngành cũng rất quan trọng. Khi hiểu rõ về lĩnh vực, modeler sẽ nắm rõ bản chất mối quan hệ của các biến không chỉ qua các con số mà còn trên các khía cạnh business thực tiễn. Đó cũng là lý do trong một dự án phân tích dữ liệu luôn cần sự tư vấn từ BA và các chuyên gia trong ngành để giúp modeler hiểu sâu hơn các qui luật tiềm ẩn bên trong dữ liệu đang hoạt động thế nào.</p>
<blockquote>
<div><p>Trong mọi mô hình có nên thực hiện Feature Engineering?</p>
</div></blockquote>
<p>Hầu hết các mô hình hiện đại đều thực hiện <em>Feature Engineering</em> trước khi huấn luyện mô hình bởi sau khi thực hiện <em>Feature Engineering</em> chúng ta sẽ có cơ hội tạo ra một mô hình mạnh hơn. Cần so sánh nhiều mô hình khác nhau để lựa chọn ra đâu là mô hình phù hợp nhất, trong một số trường hợp có thể sử dụng kết hợp các mô hình.</p>
<blockquote>
<div><p>Ý tưởng về <em>Feature Engineering</em> rất nhiều? Làm thế nào để tìm ra một <em>Feature Engineering</em> tối ưu?</p>
</div></blockquote>
<p>Không có câu trả lời cụ thể cho một phương pháp <em>Feature Engineering</em> nào là tối ưu. Chỉ có quá trình thử và sai để rút ra được phương pháp <em>Feature Engineering</em> nào sẽ phù hợp với bài toán cụ thể nào.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="tai-lieu-tham-khao">
<h1>11.6. Tài liệu tham khảo<a class="headerlink" href="#tai-lieu-tham-khao" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p><a class="reference external" href="https://mlcourse.ai/notebooks/blob/master/jupyter_english/topic06_features_regression/topic6_feature_engineering_feature_selection.ipynb?flush_cache=true">Giới thiệu về feature engineering - mlcourse.ai</a></p></li>
<li><p><a class="reference external" href="https://machinelearningcoban.com/general/2017/02/06/featureengineering/">feature engineering - blog machinelearningcoban - Vu Huu Tiep</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">tfidf - Information retrieval - wiki</a></p></li>
<li><p><a class="reference external" href="https://www.pyimagesearch.com/2017/07/10/using-tesseract-ocr-python/">package pytessaract - ứng dụng trong OCR - blog pyimagesearch</a></p></li>
<li><p><a class="reference external" href="http://hamelg.blogspot.com/2015/11/python-for-data-analysis-part-17.html">extract time in python - blog hamelg</a></p></li>
<li><p><a class="reference external" href="http://rpubs.com/phamdinhkhanh/398690">feature scaling - rpub phamdinhkhanh</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/arsenyinfo/easy-feature-selection-pipeline-0-55-at-lb">feature scaling - arsenyinfo</a></p></li>
<li><p><a class="reference external" href="https://www.analyticsvidhya.com/blog/2020/07/types-of-feature-transformation-and-scaling/">Type of feature transformation and scaling - analyticsvidhya</a></p></li>
<li><p><a class="reference external" href="https://machinelearningmastery.com/probabilistic-model-selection-measures/">Probabilistic model selection measures</a></p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/preprocessing.html">Sklearn Preprocessing</a></p></li>
</ol>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="bai-tap">
<h1>11.7. Bài tập<a class="headerlink" href="#bai-tap" title="Permalink to this headline">¶</a></h1>
<p>1-. Trong phương pháp bag-of-word thì mỗi một đoạn văn bản sẽ được biến đổi thành véc tơ đặc trưng như thế nào?</p>
<p>2-. Phương pháp bag-of-ngram với bigram và trigram sẽ mã hoá một văn bản như thế nào? Số lượng các từ trong từ điển của phương pháp bag-of-ngram sẽ lớn hơn hay nhỏ hơn so với bag-of-word?</p>
<p>3-. Giải thích ý nghĩa của chỉ số tf-idf được sử dụng để mã hoá các từ trong bộ văn bản. Một từ có tf-idf cao thì chứng tỏ điều gì?</p>
<p>4-. Thực hành phân loại văn bản dựa trên phương pháp bag-of-word và tf-idf đối với bộ dữ liệu <a class="reference external" href="https://github.com/duyvuleo/VNTC/tree/master/Data/10Topics/Ver1.1">10Topics</a>.</p>
<p>5-. Kiến trúc chung của một mạng Deep CNN trong bài toán phân loại ảnh sẽ có dạng như thế nào? Phương pháp nào thường được sử dụng để tận dụng lại tri thức từ những mô hình đã được huấn luyện trước đó nhằm tiết kiệm tài nguyên tính toán ?</p>
<p>6-. Sử dụng code python để thực hành những bài tập liên quan tới biến đổi thời gian sau:</p>
<ul class="simple">
<li><p>Lấy ra current date và current time</p></li>
<li><p>Current year</p></li>
<li><p>Month of year</p></li>
<li><p>Week number of the year</p></li>
<li><p>Weekday of the week</p></li>
<li><p>Day of year</p></li>
<li><p>Day of the month</p></li>
<li><p>Day of week</p></li>
</ul>
<p>7-. Các kĩ thuật Standardization, Min-Max Scaling, Unit Length và Robust Scaling có đặc điểm như thế nào? Ưu điểm của kĩ thuật Robust Scaling so với các kĩ thuật còn lại?</p>
<p>8-. Nêu những phương pháp chính để thực hiện lựa chọn đặc trưng cho mô hình?</p>
<p>9-. Khởi tạo một mẫu dữ liệu example với 50 đặc trưng.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>

<span class="c1"># Khởi tạo dữ liệu example</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
<p>Thực hành phương pháp Auto-Encoder để giảm chiều dữ liệu từ 50 chiều về 10 chiều. Xây dựng mô hình phân loại trên 10 đặc trưng được giảm chiều và đánh giá độ chính xác mô hình.</p>
<p>10-. Sử dụng các kĩ thuật lựa chọn đặc trưng khác nhau để lựa chọn ra 10 đặc trưng. Xây dựng mô hình phân loại trên các đặc trưng được lựa chọn và đánh giá độ chính xác.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="index_FeatureEngineering.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">11. Giới thiệu về feature engineering</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="index_Boosting.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">12. Phương pháp tăng cường (<em>Boosting</em>)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Pham Dinh Khanh<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>